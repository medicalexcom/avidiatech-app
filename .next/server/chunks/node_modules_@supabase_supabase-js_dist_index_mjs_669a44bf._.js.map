{"version":3,"sources":["../../../node_modules/iceberg-js/src/errors/IcebergError.ts","../../../node_modules/%40supabase/storage-js/src/lib/errors.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestError.ts","../../../node_modules/%40supabase/supabase-js/src/lib/version.ts","../../../node_modules/%40supabase/supabase-js/src/lib/constants.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestBuilder.ts","../../../node_modules/iceberg-js/src/utils/url.ts","../../../node_modules/%40supabase/storage-js/src/lib/helpers.ts","../../../node_modules/iceberg-js/src/http/createFetchClient.ts","../../../node_modules/%40supabase/supabase-js/src/lib/fetch.ts","../../../node_modules/iceberg-js/src/catalog/namespaces.ts","../../../node_modules/%40supabase/supabase-js/src/lib/helpers.ts","../../../node_modules/%40supabase/storage-js/src/lib/fetch.ts","../../../node_modules/%40supabase/supabase-js/src/lib/SupabaseAuthClient.ts","../../../node_modules/%40supabase/supabase-js/src/SupabaseClient.ts","../../../node_modules/iceberg-js/src/catalog/tables.ts","../../../node_modules/%40supabase/storage-js/src/packages/StreamDownloadBuilder.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestTransformBuilder.ts","../../../node_modules/%40supabase/storage-js/src/packages/BlobDownloadBuilder.ts","../../../node_modules/iceberg-js/src/catalog/IcebergRestCatalog.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageFileApi.ts","../../../node_modules/%40supabase/supabase-js/src/index.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestFilterBuilder.ts","../../../node_modules/iceberg-js/src/catalog/types.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestQueryBuilder.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestClient.ts","../../../node_modules/%40supabase/storage-js/src/lib/version.ts","../../../node_modules/%40supabase/storage-js/src/lib/constants.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageBucketApi.ts","../../../node_modules/%40supabase/postgrest-js/src/index.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageAnalyticsClient.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/constants.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/errors.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/helpers.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/fetch.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorIndexApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorDataApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorBucketApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/StorageVectorsClient.ts","../../../node_modules/%40supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["export interface IcebergErrorResponse {\n  error: {\n    message: string\n    type: string\n    code: number\n    stack?: string[]\n  }\n}\n\nexport class IcebergError extends Error {\n  readonly status: number\n  readonly icebergType?: string\n  readonly icebergCode?: number\n  readonly details?: unknown\n  readonly isCommitStateUnknown: boolean\n\n  constructor(\n    message: string,\n    opts: {\n      status: number\n      icebergType?: string\n      icebergCode?: number\n      details?: unknown\n    }\n  ) {\n    super(message)\n    this.name = 'IcebergError'\n    this.status = opts.status\n    this.icebergType = opts.icebergType\n    this.icebergCode = opts.icebergCode\n    this.details = opts.details\n\n    // Detect CommitStateUnknownException (500, 502, 504 during table commits)\n    this.isCommitStateUnknown =\n      opts.icebergType === 'CommitStateUnknownException' ||\n      ([500, 502, 504].includes(opts.status) && opts.icebergType?.includes('CommitState') === true)\n  }\n\n  /**\n   * Returns true if the error is a 404 Not Found error.\n   */\n  isNotFound(): boolean {\n    return this.status === 404\n  }\n\n  /**\n   * Returns true if the error is a 409 Conflict error.\n   */\n  isConflict(): boolean {\n    return this.status === 409\n  }\n\n  /**\n   * Returns true if the error is a 419 Authentication Timeout error.\n   */\n  isAuthenticationTimeout(): boolean {\n    return this.status === 419\n  }\n}\n","export class StorageError extends Error {\n  protected __isStorageError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageError'\n  }\n}\n\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\nexport class StorageApiError extends StorageError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n","/**\n * Error format\n *\n * {@link https://postgrest.org/en/stable/api.html?highlight=options#errors-and-http-status-codes}\n */\nexport default class PostgrestError extends Error {\n  details: string\n  hint: string\n  code: string\n\n  /**\n   * @example\n   * ```ts\n   * import PostgrestError from '@supabase/postgrest-js'\n   *\n   * throw new PostgrestError({\n   *   message: 'Row level security prevented the request',\n   *   details: 'RLS denied the insert',\n   *   hint: 'Check your policies',\n   *   code: 'PGRST301',\n   * })\n   * ```\n   */\n  constructor(context: { message: string; details: string; hint: string; code: string }) {\n    super(context.message)\n    this.name = 'PostgrestError'\n    this.details = context.details\n    this.hint = context.hint\n    this.code = context.code\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.89.0'\n","// constants.ts\nimport { RealtimeClientOptions } from '@supabase/realtime-js'\nimport { SupabaseAuthClientOptions } from './types'\nimport { version } from './version'\n\nlet JS_ENV = ''\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n  JS_ENV = 'deno'\n} else if (typeof document !== 'undefined') {\n  JS_ENV = 'web'\n} else if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n  JS_ENV = 'react-native'\n} else {\n  JS_ENV = 'node'\n}\n\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${version}` }\n\nexport const DEFAULT_GLOBAL_OPTIONS = {\n  headers: DEFAULT_HEADERS,\n}\n\nexport const DEFAULT_DB_OPTIONS = {\n  schema: 'public',\n}\n\nexport const DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions = {\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n  flowType: 'implicit',\n}\n\nexport const DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions = {}\n","import type {\n  PostgrestSingleResponse,\n  PostgrestResponseSuccess,\n  CheckMatchingArrayTypes,\n  MergePartialResult,\n  IsValidResultOverride,\n} from './types/types'\nimport { ClientServerOptions, Fetch } from './types/common/common'\nimport PostgrestError from './PostgrestError'\nimport { ContainsNull } from './select-query-parser/types'\n\nexport default abstract class PostgrestBuilder<\n  ClientOptions extends ClientServerOptions,\n  Result,\n  ThrowOnError extends boolean = false,\n> implements\n    PromiseLike<\n      ThrowOnError extends true ? PostgrestResponseSuccess<Result> : PostgrestSingleResponse<Result>\n    >\n{\n  protected method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n  protected url: URL\n  protected headers: Headers\n  protected schema?: string\n  protected body?: unknown\n  protected shouldThrowOnError = false\n  protected signal?: AbortSignal\n  protected fetch: Fetch\n  protected isMaybeSingle: boolean\n\n  /**\n   * Creates a builder configured for a specific PostgREST request.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const builder = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: new Headers({ apikey: 'public-anon-key' }) }\n   * )\n   * ```\n   */\n  constructor(builder: {\n    method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n    url: URL\n    headers: HeadersInit\n    schema?: string\n    body?: unknown\n    shouldThrowOnError?: boolean\n    signal?: AbortSignal\n    fetch?: Fetch\n    isMaybeSingle?: boolean\n  }) {\n    this.method = builder.method\n    this.url = builder.url\n    this.headers = new Headers(builder.headers)\n    this.schema = builder.schema\n    this.body = builder.body\n    this.shouldThrowOnError = builder.shouldThrowOnError ?? false\n    this.signal = builder.signal\n    this.isMaybeSingle = builder.isMaybeSingle ?? false\n\n    if (builder.fetch) {\n      this.fetch = builder.fetch\n    } else {\n      this.fetch = fetch\n    }\n  }\n\n  /**\n   * If there's an error with the query, throwOnError will reject the promise by\n   * throwing the error instead of returning it as part of a successful response.\n   *\n   * {@link https://github.com/supabase/supabase-js/issues/92}\n   */\n  throwOnError(): this & PostgrestBuilder<ClientOptions, Result, true> {\n    this.shouldThrowOnError = true\n    return this as this & PostgrestBuilder<ClientOptions, Result, true>\n  }\n\n  /**\n   * Set an HTTP header for the request.\n   */\n  setHeader(name: string, value: string): this {\n    this.headers = new Headers(this.headers)\n    this.headers.set(name, value)\n    return this\n  }\n\n  then<\n    TResult1 = ThrowOnError extends true\n      ? PostgrestResponseSuccess<Result>\n      : PostgrestSingleResponse<Result>,\n    TResult2 = never,\n  >(\n    onfulfilled?:\n      | ((\n          value: ThrowOnError extends true\n            ? PostgrestResponseSuccess<Result>\n            : PostgrestSingleResponse<Result>\n        ) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): PromiseLike<TResult1 | TResult2> {\n    // https://postgrest.org/en/stable/api.html#switching-schemas\n    if (this.schema === undefined) {\n      // skip\n    } else if (['GET', 'HEAD'].includes(this.method)) {\n      this.headers.set('Accept-Profile', this.schema)\n    } else {\n      this.headers.set('Content-Profile', this.schema)\n    }\n    if (this.method !== 'GET' && this.method !== 'HEAD') {\n      this.headers.set('Content-Type', 'application/json')\n    }\n\n    // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n    // https://github.com/supabase/postgrest-js/pull/247\n    const _fetch = this.fetch\n    let res = _fetch(this.url.toString(), {\n      method: this.method,\n      headers: this.headers,\n      body: JSON.stringify(this.body),\n      signal: this.signal,\n    }).then(async (res) => {\n      let error = null\n      let data = null\n      let count: number | null = null\n      let status = res.status\n      let statusText = res.statusText\n\n      if (res.ok) {\n        if (this.method !== 'HEAD') {\n          const body = await res.text()\n          if (body === '') {\n            // Prefer: return=minimal\n          } else if (this.headers.get('Accept') === 'text/csv') {\n            data = body\n          } else if (\n            this.headers.get('Accept') &&\n            this.headers.get('Accept')?.includes('application/vnd.pgrst.plan+text')\n          ) {\n            data = body\n          } else {\n            data = JSON.parse(body)\n          }\n        }\n\n        const countHeader = this.headers.get('Prefer')?.match(/count=(exact|planned|estimated)/)\n        const contentRange = res.headers.get('content-range')?.split('/')\n        if (countHeader && contentRange && contentRange.length > 1) {\n          count = parseInt(contentRange[1])\n        }\n\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n          if (data.length > 1) {\n            error = {\n              // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n              code: 'PGRST116',\n              details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n              hint: null,\n              message: 'JSON object requested, multiple (or no) rows returned',\n            }\n            data = null\n            count = null\n            status = 406\n            statusText = 'Not Acceptable'\n          } else if (data.length === 1) {\n            data = data[0]\n          } else {\n            data = null\n          }\n        }\n      } else {\n        const body = await res.text()\n\n        try {\n          error = JSON.parse(body)\n\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (Array.isArray(error) && res.status === 404) {\n            data = []\n            error = null\n            status = 200\n            statusText = 'OK'\n          }\n        } catch {\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (res.status === 404 && body === '') {\n            status = 204\n            statusText = 'No Content'\n          } else {\n            error = {\n              message: body,\n            }\n          }\n        }\n\n        if (error && this.isMaybeSingle && error?.details?.includes('0 rows')) {\n          error = null\n          status = 200\n          statusText = 'OK'\n        }\n\n        if (error && this.shouldThrowOnError) {\n          throw new PostgrestError(error)\n        }\n      }\n\n      const postgrestResponse = {\n        error,\n        data,\n        count,\n        status,\n        statusText,\n      }\n\n      return postgrestResponse\n    })\n    if (!this.shouldThrowOnError) {\n      res = res.catch((fetchError) => {\n        // Build detailed error information including cause if available\n        // Note: We don't populate code/hint for client-side network errors since those\n        // fields are meant for upstream service errors (PostgREST/PostgreSQL)\n        let errorDetails = ''\n\n        // Add cause information if available (e.g., DNS errors, network failures)\n        const cause = fetchError?.cause\n        if (cause) {\n          const causeMessage = cause?.message ?? ''\n          const causeCode = cause?.code ?? ''\n\n          errorDetails = `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`\n          errorDetails += `\\n\\nCaused by: ${cause?.name ?? 'Error'}: ${causeMessage}`\n          if (causeCode) {\n            errorDetails += ` (${causeCode})`\n          }\n          if (cause?.stack) {\n            errorDetails += `\\n${cause.stack}`\n          }\n        } else {\n          // No cause available, just include the error stack\n          errorDetails = fetchError?.stack ?? ''\n        }\n\n        return {\n          error: {\n            message: `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`,\n            details: errorDetails,\n            hint: '',\n            code: '',\n          },\n          data: null,\n          count: null,\n          status: 0,\n          statusText: '',\n        }\n      })\n    }\n\n    return res.then(onfulfilled, onrejected)\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestBuilder<\n    ClientOptions,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    /* istanbul ignore next */\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n\n  /**\n   * Override the type of the returned `data` field in the response.\n   *\n   * @typeParam NewResult - The new type to cast the response data to\n   * @typeParam Options - Optional type configuration (defaults to { merge: true })\n   * @typeParam Options.merge - When true, merges the new type with existing return type. When false, replaces the existing types entirely (defaults to true)\n   * @example\n   * ```typescript\n   * // Merge with existing types (default behavior)\n   * const query = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ custom_field: string }>()\n   *\n   * // Replace existing types completely\n   * const replaceQuery = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ id: number; name: string }, { merge: false }>()\n   * ```\n   * @returns A PostgrestBuilder instance with the new type\n   */\n  overrideTypes<\n    NewResult,\n    Options extends { merge?: boolean } = { merge: true },\n  >(): PostgrestBuilder<\n    ClientOptions,\n    IsValidResultOverride<Result, NewResult, false, false> extends true\n      ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n        ContainsNull<Result> extends true\n        ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n        : MergePartialResult<NewResult, Result, Options>\n      : CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      IsValidResultOverride<Result, NewResult, false, false> extends true\n        ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n          ContainsNull<Result> extends true\n          ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n          : MergePartialResult<NewResult, Result, Options>\n        : CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n}\n","export function buildUrl(\n  baseUrl: string,\n  path: string,\n  query?: Record<string, string | undefined>\n): string {\n  const url = new URL(path, baseUrl)\n\n  if (query) {\n    for (const [key, value] of Object.entries(query)) {\n      if (value !== undefined) {\n        url.searchParams.set(key, value)\n      }\n    }\n  }\n\n  return url.toString()\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n * source: https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n","import { IcebergError, type IcebergErrorResponse } from '../errors/IcebergError'\nimport { buildUrl } from '../utils/url'\nimport type { AuthConfig, HttpClient, HttpRequest, HttpResponse } from './types'\n\nasync function buildAuthHeaders(auth?: AuthConfig): Promise<Record<string, string>> {\n  if (!auth || auth.type === 'none') {\n    return {}\n  }\n\n  if (auth.type === 'bearer') {\n    return { Authorization: `Bearer ${auth.token}` }\n  }\n\n  if (auth.type === 'header') {\n    return { [auth.name]: auth.value }\n  }\n\n  if (auth.type === 'custom') {\n    return await auth.getHeaders()\n  }\n\n  return {}\n}\n\nexport function createFetchClient(options: {\n  baseUrl: string\n  auth?: AuthConfig\n  fetchImpl?: typeof fetch\n}): HttpClient {\n  const fetchFn = options.fetchImpl ?? globalThis.fetch\n\n  return {\n    async request<T>({\n      method,\n      path,\n      query,\n      body,\n      headers,\n    }: HttpRequest): Promise<HttpResponse<T>> {\n      const url = buildUrl(options.baseUrl, path, query)\n      const authHeaders = await buildAuthHeaders(options.auth)\n\n      const res = await fetchFn(url, {\n        method,\n        headers: {\n          ...(body ? { 'Content-Type': 'application/json' } : {}),\n          ...authHeaders,\n          ...headers,\n        },\n        body: body ? JSON.stringify(body) : undefined,\n      })\n\n      const text = await res.text()\n      const isJson = (res.headers.get('content-type') || '').includes('application/json')\n      const data = isJson && text ? (JSON.parse(text) as T) : (text as T)\n\n      if (!res.ok) {\n        const errBody = isJson ? (data as IcebergErrorResponse) : undefined\n        const errorDetail = errBody?.error\n        throw new IcebergError(\n          errorDetail?.message ?? `Request failed with status ${res.status}`,\n          {\n            status: res.status,\n            icebergType: errorDetail?.type,\n            icebergCode: errorDetail?.code,\n            details: errBody,\n          }\n        )\n      }\n\n      return { status: res.status, headers: res.headers, data: data as T }\n    },\n  }\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args: Parameters<Fetch>) => customFetch(...args)\n  }\n  return (...args: Parameters<Fetch>) => fetch(...args)\n}\n\nexport const resolveHeadersConstructor = () => {\n  return Headers\n}\n\nexport const fetchWithAuth = (\n  supabaseKey: string,\n  getAccessToken: () => Promise<string | null>,\n  customFetch?: Fetch\n): Fetch => {\n  const fetch = resolveFetch(customFetch)\n  const HeadersConstructor = resolveHeadersConstructor()\n\n  return async (input, init) => {\n    const accessToken = (await getAccessToken()) ?? supabaseKey\n    let headers = new HeadersConstructor(init?.headers)\n\n    if (!headers.has('apikey')) {\n      headers.set('apikey', supabaseKey)\n    }\n\n    if (!headers.has('Authorization')) {\n      headers.set('Authorization', `Bearer ${accessToken}`)\n    }\n\n    return fetch(input, { ...init, headers })\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateNamespaceRequest,\n  CreateNamespaceResponse,\n  GetNamespaceResponse,\n  ListNamespacesResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class NamespaceOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = ''\n  ) {}\n\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    const query = parent ? { parent: namespaceToPath(parent.namespace) } : undefined\n\n    const response = await this.client.request<ListNamespacesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces`,\n      query,\n    })\n\n    return response.data.namespaces.map((ns) => ({ namespace: ns }))\n  }\n\n  async createNamespace(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse> {\n    const request: CreateNamespaceRequest = {\n      namespace: id.namespace,\n      properties: metadata?.properties,\n    }\n\n    const response = await this.client.request<CreateNamespaceResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces`,\n      body: request,\n    })\n\n    return response.data\n  }\n\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n  }\n\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    const response = await this.client.request<GetNamespaceResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n\n    return {\n      properties: response.data.properties,\n    }\n  }\n\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    try {\n      return await this.createNamespace(id, metadata)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return\n      }\n      throw error\n    }\n  }\n}\n","// helpers.ts\nimport { SupabaseClientOptions } from './types'\n\nexport function uuid() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    var r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8\n    return v.toString(16)\n  })\n}\n\nexport function ensureTrailingSlash(url: string): string {\n  return url.endsWith('/') ? url : url + '/'\n}\n\nexport const isBrowser = () => typeof window !== 'undefined'\n\nexport function applySettingDefaults<\n  Database = any,\n  SchemaName extends string & keyof Database = 'public' extends keyof Database\n    ? 'public'\n    : string & keyof Database,\n>(\n  options: SupabaseClientOptions<SchemaName>,\n  defaults: SupabaseClientOptions<any>\n): Required<SupabaseClientOptions<SchemaName>> {\n  const {\n    db: dbOptions,\n    auth: authOptions,\n    realtime: realtimeOptions,\n    global: globalOptions,\n  } = options\n  const {\n    db: DEFAULT_DB_OPTIONS,\n    auth: DEFAULT_AUTH_OPTIONS,\n    realtime: DEFAULT_REALTIME_OPTIONS,\n    global: DEFAULT_GLOBAL_OPTIONS,\n  } = defaults\n\n  const result: Required<SupabaseClientOptions<SchemaName>> = {\n    db: {\n      ...DEFAULT_DB_OPTIONS,\n      ...dbOptions,\n    },\n    auth: {\n      ...DEFAULT_AUTH_OPTIONS,\n      ...authOptions,\n    },\n    realtime: {\n      ...DEFAULT_REALTIME_OPTIONS,\n      ...realtimeOptions,\n    },\n    storage: {},\n    global: {\n      ...DEFAULT_GLOBAL_OPTIONS,\n      ...globalOptions,\n      headers: {\n        ...(DEFAULT_GLOBAL_OPTIONS?.headers ?? {}),\n        ...(globalOptions?.headers ?? {}),\n      },\n    },\n    accessToken: async () => '',\n  }\n\n  if (options.accessToken) {\n    result.accessToken = options.accessToken\n  } else {\n    // hack around Required<>\n    delete (result as any).accessToken\n  }\n\n  return result\n}\n\n/**\n * Validates a Supabase client URL\n *\n * @param {string} supabaseUrl - The Supabase client URL string.\n * @returns {URL} - The validated base URL.\n * @throws {Error}\n */\nexport function validateSupabaseUrl(supabaseUrl: string): URL {\n  const trimmedUrl = supabaseUrl?.trim()\n\n  if (!trimmedUrl) {\n    throw new Error('supabaseUrl is required.')\n  }\n\n  if (!trimmedUrl.match(/^https?:\\/\\//i)) {\n    throw new Error('Invalid supabaseUrl: Must be a valid HTTP or HTTPS URL.')\n  }\n\n  try {\n    return new URL(ensureTrailingSlash(trimmedUrl))\n  } catch {\n    throw Error('Invalid supabaseUrl: Provided URL is malformed.')\n  }\n}\n","import { StorageApiError, StorageUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  const Res = await resolveResponse()\n\n  if (error instanceof Res && !options?.noResolveJson) {\n    error\n      .json()\n      .then((err) => {\n        const status = error.status || 500\n        const statusCode = err?.statusCode || status + ''\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode))\n      })\n      .catch((err) => {\n        reject(new StorageUnknownError(_getErrorMessage(err), err))\n      })\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error))\n  }\n}\n\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\nexport async function head(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(\n    fetcher,\n    'HEAD',\n    url,\n    {\n      ...options,\n      noResolveJson: true,\n    },\n    parameters\n  )\n}\n\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { AuthClient } from '@supabase/auth-js'\nimport { SupabaseAuthClientOptions } from './types'\n\nexport class SupabaseAuthClient extends AuthClient {\n  constructor(options: SupabaseAuthClientOptions) {\n    super(options)\n  }\n}\n","import type { AuthChangeEvent } from '@supabase/auth-js'\nimport { FunctionsClient } from '@supabase/functions-js'\nimport {\n  PostgrestClient,\n  type PostgrestFilterBuilder,\n  type PostgrestQueryBuilder,\n} from '@supabase/postgrest-js'\nimport {\n  type RealtimeChannel,\n  type RealtimeChannelOptions,\n  RealtimeClient,\n  type RealtimeClientOptions,\n} from '@supabase/realtime-js'\nimport { StorageClient as SupabaseStorageClient } from '@supabase/storage-js'\nimport {\n  DEFAULT_AUTH_OPTIONS,\n  DEFAULT_DB_OPTIONS,\n  DEFAULT_GLOBAL_OPTIONS,\n  DEFAULT_REALTIME_OPTIONS,\n} from './lib/constants'\nimport { fetchWithAuth } from './lib/fetch'\nimport { applySettingDefaults, validateSupabaseUrl } from './lib/helpers'\nimport { SupabaseAuthClient } from './lib/SupabaseAuthClient'\nimport type {\n  Fetch,\n  GenericSchema,\n  SupabaseAuthClientOptions,\n  SupabaseClientOptions,\n} from './lib/types'\nimport { GetRpcFunctionFilterBuilderByArgs } from './lib/rest/types/common/rpc'\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nexport default class SupabaseClient<\n  Database = any,\n  // The second type parameter is also used for specifying db_schema, so we\n  // support both cases.\n  // TODO: Allow setting db_schema from ClientOptions.\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n  Schema extends Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never = Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never,\n  ClientOptions extends { PostgrestVersion: string } = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? // If the version isn't explicitly set, look for it in the __InternalSupabase object to infer the right version\n      Database extends { __InternalSupabase: { PostgrestVersion: string } }\n      ? Database['__InternalSupabase']\n      : // otherwise default to 12\n        { PostgrestVersion: '12' }\n    : SchemaNameOrClientOptions extends { PostgrestVersion: string }\n      ? SchemaNameOrClientOptions\n      : never,\n> {\n  /**\n   * Supabase Auth allows you to create and manage user sessions for access to data that is secured by access policies.\n   */\n  auth: SupabaseAuthClient\n  realtime: RealtimeClient\n  /**\n   * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n   */\n  storage: SupabaseStorageClient\n\n  protected realtimeUrl: URL\n  protected authUrl: URL\n  protected storageUrl: URL\n  protected functionsUrl: URL\n  protected rest: PostgrestClient<Database, ClientOptions, SchemaName>\n  protected storageKey: string\n  protected fetch?: Fetch\n  protected changedAccessToken?: string\n  protected accessToken?: () => Promise<string | null>\n\n  protected headers: Record<string, string>\n\n  /**\n   * Create a new client for use in the browser.\n   * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n   * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n   * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n   * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n   * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n   * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n   * @param options.realtime Options passed along to realtime-js constructor.\n   * @param options.storage Options passed along to the storage-js constructor.\n   * @param options.global.fetch A custom fetch implementation.\n   * @param options.global.headers Any additional headers to send with each network request.\n   * @example\n   * ```ts\n   * import { createClient } from '@supabase/supabase-js'\n   *\n   * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n   * const { data } = await supabase.from('profiles').select('*')\n   * ```\n   */\n  constructor(\n    protected supabaseUrl: string,\n    protected supabaseKey: string,\n    options?: SupabaseClientOptions<SchemaName>\n  ) {\n    const baseUrl = validateSupabaseUrl(supabaseUrl)\n    if (!supabaseKey) throw new Error('supabaseKey is required.')\n\n    this.realtimeUrl = new URL('realtime/v1', baseUrl)\n    this.realtimeUrl.protocol = this.realtimeUrl.protocol.replace('http', 'ws')\n    this.authUrl = new URL('auth/v1', baseUrl)\n    this.storageUrl = new URL('storage/v1', baseUrl)\n    this.functionsUrl = new URL('functions/v1', baseUrl)\n\n    // default storage key uses the supabase project ref as a namespace\n    const defaultStorageKey = `sb-${baseUrl.hostname.split('.')[0]}-auth-token`\n    const DEFAULTS = {\n      db: DEFAULT_DB_OPTIONS,\n      realtime: DEFAULT_REALTIME_OPTIONS,\n      auth: { ...DEFAULT_AUTH_OPTIONS, storageKey: defaultStorageKey },\n      global: DEFAULT_GLOBAL_OPTIONS,\n    }\n\n    const settings = applySettingDefaults(options ?? {}, DEFAULTS)\n\n    this.storageKey = settings.auth.storageKey ?? ''\n    this.headers = settings.global.headers ?? {}\n\n    if (!settings.accessToken) {\n      this.auth = this._initSupabaseAuthClient(\n        settings.auth ?? {},\n        this.headers,\n        settings.global.fetch\n      )\n    } else {\n      this.accessToken = settings.accessToken\n\n      this.auth = new Proxy<SupabaseAuthClient>({} as any, {\n        get: (_, prop) => {\n          throw new Error(\n            `@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(\n              prop\n            )} is not possible`\n          )\n        },\n      })\n    }\n\n    this.fetch = fetchWithAuth(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch)\n    this.realtime = this._initRealtimeClient({\n      headers: this.headers,\n      accessToken: this._getAccessToken.bind(this),\n      ...settings.realtime,\n    })\n    if (this.accessToken) {\n      // Start auth immediately to avoid race condition with channel subscriptions\n      this.accessToken()\n        .then((token) => this.realtime.setAuth(token))\n        .catch((e) => console.warn('Failed to set initial Realtime auth token:', e))\n    }\n\n    this.rest = new PostgrestClient(new URL('rest/v1', baseUrl).href, {\n      headers: this.headers,\n      schema: settings.db.schema,\n      fetch: this.fetch,\n    })\n\n    this.storage = new SupabaseStorageClient(\n      this.storageUrl.href,\n      this.headers,\n      this.fetch,\n      options?.storage\n    )\n\n    if (!settings.accessToken) {\n      this._listenForAuthEvents()\n    }\n  }\n\n  /**\n   * Supabase Functions allows you to deploy and invoke edge functions.\n   */\n  get functions(): FunctionsClient {\n    return new FunctionsClient(this.functionsUrl.href, {\n      headers: this.headers,\n      customFetch: this.fetch,\n    })\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.from\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any> {\n    return this.rest.from(relation)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.schema\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return this.rest.schema<DynamicSchema>(schema)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    options: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {\n      head: false,\n      get: false,\n      count: undefined,\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    return this.rest.rpc(fn, args, options) as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      FilterBuilder['Row'],\n      FilterBuilder['Result'],\n      FilterBuilder['RelationName'],\n      FilterBuilder['Relationships'],\n      'RPC'\n    >\n  }\n\n  /**\n   * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n   *\n   * @param {string} name - The name of the Realtime channel.\n   * @param {Object} opts - The options to pass to the Realtime channel.\n   *\n   */\n  channel(name: string, opts: RealtimeChannelOptions = { config: {} }): RealtimeChannel {\n    return this.realtime.channel(name, opts)\n  }\n\n  /**\n   * Returns all Realtime channels.\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.realtime.getChannels()\n  }\n\n  /**\n   * Unsubscribes and removes Realtime channel from Realtime client.\n   *\n   * @param {RealtimeChannel} channel - The name of the Realtime channel.\n   *\n   */\n  removeChannel(channel: RealtimeChannel): Promise<'ok' | 'timed out' | 'error'> {\n    return this.realtime.removeChannel(channel)\n  }\n\n  /**\n   * Unsubscribes and removes all Realtime channels from Realtime client.\n   */\n  removeAllChannels(): Promise<('ok' | 'timed out' | 'error')[]> {\n    return this.realtime.removeAllChannels()\n  }\n\n  private async _getAccessToken() {\n    if (this.accessToken) {\n      return await this.accessToken()\n    }\n\n    const { data } = await this.auth.getSession()\n\n    return data.session?.access_token ?? this.supabaseKey\n  }\n\n  private _initSupabaseAuthClient(\n    {\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      storageKey,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n    }: SupabaseAuthClientOptions,\n    headers?: Record<string, string>,\n    fetch?: Fetch\n  ) {\n    const authHeaders = {\n      Authorization: `Bearer ${this.supabaseKey}`,\n      apikey: `${this.supabaseKey}`,\n    }\n    return new SupabaseAuthClient({\n      url: this.authUrl.href,\n      headers: { ...authHeaders, ...headers },\n      storageKey: storageKey,\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n      fetch,\n      // auth checks if there is a custom authorizaiton header using this flag\n      // so it knows whether to return an error when getUser is called with no session\n      hasCustomAuthorizationHeader: Object.keys(this.headers).some(\n        (key) => key.toLowerCase() === 'authorization'\n      ),\n    })\n  }\n\n  private _initRealtimeClient(options: RealtimeClientOptions) {\n    return new RealtimeClient(this.realtimeUrl.href, {\n      ...options,\n      params: { ...{ apikey: this.supabaseKey }, ...options?.params },\n    })\n  }\n\n  private _listenForAuthEvents() {\n    const data = this.auth.onAuthStateChange((event, session) => {\n      this._handleTokenChanged(event, 'CLIENT', session?.access_token)\n    })\n    return data\n  }\n\n  private _handleTokenChanged(\n    event: AuthChangeEvent,\n    source: 'CLIENT' | 'STORAGE',\n    token?: string\n  ) {\n    if (\n      (event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n      this.changedAccessToken !== token\n    ) {\n      this.changedAccessToken = token\n      this.realtime.setAuth(token)\n    } else if (event === 'SIGNED_OUT') {\n      this.realtime.setAuth()\n      if (source == 'STORAGE') this.auth.signOut()\n      this.changedAccessToken = undefined\n    }\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateTableRequest,\n  CommitTableResponse,\n  ListTablesResponse,\n  LoadTableResponse,\n  NamespaceIdentifier,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class TableOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = '',\n    private readonly accessDelegation?: string\n  ) {}\n\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    const response = await this.client.request<ListTablesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n    })\n\n    return response.data.identifiers\n  }\n\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n      body: request,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      body: request,\n    })\n\n    return {\n      'metadata-location': response.data['metadata-location'],\n      metadata: response.data.metadata,\n    }\n  }\n\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      query: { purgeRequested: String(options?.purge ?? false) },\n    })\n  }\n\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n        headers,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    try {\n      return await this.createTable(namespace, request)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return await this.loadTable({ namespace: namespace.namespace, name: request.name })\n      }\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestFilterBuilder, { InvalidMethodError } from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport { CheckMatchingArrayTypes } from './types/types'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\nimport type { MaxAffectedEnabled } from './types/feature-flags'\n\nexport default class PostgrestTransformBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestBuilder<ClientOptions, Result> {\n  /**\n   * Perform a SELECT on the query result.\n   *\n   * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n   * return modified rows. By calling this method, modified rows are returned in\n   * `data`.\n   *\n   * @param columns - The columns to retrieve, separated by commas\n   */\n  select<\n    Query extends string = '*',\n    NewResultOne = GetResult<Schema, Row, RelationName, Relationships, Query, ClientOptions>,\n  >(\n    columns?: Query\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    Method extends 'RPC'\n      ? Result extends unknown[]\n        ? NewResultOne[]\n        : NewResultOne\n      : NewResultOne[],\n    RelationName,\n    Relationships,\n    Method\n  > {\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n    this.headers.append('Prefer', 'return=representation')\n    return this as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      Method extends 'RPC'\n        ? Result extends unknown[]\n          ? NewResultOne[]\n          : NewResultOne\n        : NewResultOne[],\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: undefined }\n  ): this\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: string }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: undefined }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: string }\n  ): this\n  /**\n   * Order the query result by `column`.\n   *\n   * You can call this method multiple times to order by multiple columns.\n   *\n   * You can order referenced tables, but it only affects the ordering of the\n   * parent table if you use `!inner` in the query.\n   *\n   * @param column - The column to order by\n   * @param options - Named parameters\n   * @param options.ascending - If `true`, the result will be in ascending order\n   * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n   * `null`s appear last.\n   * @param options.referencedTable - Set this to order a referenced table by\n   * its columns\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  order(\n    column: string,\n    {\n      ascending = true,\n      nullsFirst,\n      foreignTable,\n      referencedTable = foreignTable,\n    }: {\n      ascending?: boolean\n      nullsFirst?: boolean\n      foreignTable?: string\n      referencedTable?: string\n    } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.order` : 'order'\n    const existingOrder = this.url.searchParams.get(key)\n\n    this.url.searchParams.set(\n      key,\n      `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${\n        nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'\n      }`\n    )\n    return this\n  }\n\n  /**\n   * Limit the query result by `count`.\n   *\n   * @param count - The maximum number of rows to return\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  limit(\n    count: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(key, `${count}`)\n    return this\n  }\n\n  /**\n   * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n   * Only records within this range are returned.\n   * This respects the query order and if there is no order clause the range could behave unexpectedly.\n   * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n   * and fourth rows of the query.\n   *\n   * @param from - The starting index from which to limit the result\n   * @param to - The last index to which to limit the result\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  range(\n    from: number,\n    to: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const keyOffset =\n      typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`\n    const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(keyOffset, `${from}`)\n    // Range is inclusive, so add 1\n    this.url.searchParams.set(keyLimit, `${to - from + 1}`)\n    return this\n  }\n\n  /**\n   * Set the AbortSignal for the fetch request.\n   *\n   * @param signal - The AbortSignal to use for the fetch request\n   */\n  abortSignal(signal: AbortSignal): this {\n    this.signal = signal\n    return this\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n   * returns an error.\n   */\n  single<ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never>(): PostgrestBuilder<\n    ClientOptions,\n    ResultOne\n  > {\n    this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne>\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n   * this returns an error.\n   */\n  maybeSingle<\n    ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never,\n  >(): PostgrestBuilder<ClientOptions, ResultOne | null> {\n    // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n    // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n    if (this.method === 'GET') {\n      this.headers.set('Accept', 'application/json')\n    } else {\n      this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    }\n    this.isMaybeSingle = true\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne | null>\n  }\n\n  /**\n   * Return `data` as a string in CSV format.\n   */\n  csv(): PostgrestBuilder<ClientOptions, string> {\n    this.headers.set('Accept', 'text/csv')\n    return this as unknown as PostgrestBuilder<ClientOptions, string>\n  }\n\n  /**\n   * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n   */\n  geojson(): PostgrestBuilder<ClientOptions, Record<string, unknown>> {\n    this.headers.set('Accept', 'application/geo+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>>\n  }\n\n  /**\n   * Return `data` as the EXPLAIN plan for the query.\n   *\n   * You need to enable the\n   * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n   * setting before using this method.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.analyze - If `true`, the query will be executed and the\n   * actual run time will be returned\n   *\n   * @param options.verbose - If `true`, the query identifier will be returned\n   * and `data` will include the output columns of the query\n   *\n   * @param options.settings - If `true`, include information on configuration\n   * parameters that affect query planning\n   *\n   * @param options.buffers - If `true`, include information on buffer usage\n   *\n   * @param options.wal - If `true`, include information on WAL record generation\n   *\n   * @param options.format - The format of the output, can be `\"text\"` (default)\n   * or `\"json\"`\n   */\n  explain({\n    analyze = false,\n    verbose = false,\n    settings = false,\n    buffers = false,\n    wal = false,\n    format = 'text',\n  }: {\n    analyze?: boolean\n    verbose?: boolean\n    settings?: boolean\n    buffers?: boolean\n    wal?: boolean\n    format?: 'json' | 'text'\n  } = {}) {\n    const options = [\n      analyze ? 'analyze' : null,\n      verbose ? 'verbose' : null,\n      settings ? 'settings' : null,\n      buffers ? 'buffers' : null,\n      wal ? 'wal' : null,\n    ]\n      .filter(Boolean)\n      .join('|')\n    // An Accept header can carry multiple media types but postgrest-js always sends one\n    const forMediatype = this.headers.get('Accept') ?? 'application/json'\n    this.headers.set(\n      'Accept',\n      `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`\n    )\n    if (format === 'json') {\n      return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>[]>\n    } else {\n      return this as unknown as PostgrestBuilder<ClientOptions, string>\n    }\n  }\n\n  /**\n   * Rollback the query.\n   *\n   * `data` will still be returned, but the query is not committed.\n   */\n  rollback(): this {\n    this.headers.append('Prefer', 'tx=rollback')\n    return this\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    RelationName,\n    Relationships,\n    Method\n  > {\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  /**\n   * Set the maximum number of rows that can be affected by the query.\n   * Only available in PostgREST v13+ and only works with PATCH and DELETE methods.\n   *\n   * @param value - The maximum number of rows that can be affected\n   */\n  maxAffected(value: number): MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n    ? // TODO: update the RPC case to only work on RPC that returns SETOF rows\n      Method extends 'PATCH' | 'DELETE' | 'RPC'\n      ? this\n      : InvalidMethodError<'maxAffected method only available on update or delete'>\n    : InvalidMethodError<'maxAffected method only available on postgrest 13+'> {\n    this.headers.append('Prefer', 'handling=strict')\n    this.headers.append('Prefer', `max-affected=${value}`)\n    return this as unknown as MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n      ? Method extends 'PATCH' | 'DELETE' | 'RPC'\n        ? this\n        : InvalidMethodError<'maxAffected method only available on update or delete'>\n      : InvalidMethodError<'maxAffected method only available on postgrest 13+'>\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { createFetchClient } from '../http/createFetchClient'\nimport type { AuthConfig, HttpClient } from '../http/types'\nimport { NamespaceOperations } from './namespaces'\nimport { TableOperations } from './tables'\nimport type {\n  CreateTableRequest,\n  CreateNamespaceResponse,\n  CommitTableResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\n/**\n * Access delegation mechanisms supported by the Iceberg REST Catalog.\n *\n * - `vended-credentials`: Server provides temporary credentials for data access\n * - `remote-signing`: Server signs requests on behalf of the client\n */\nexport type AccessDelegation = 'vended-credentials' | 'remote-signing'\n\n/**\n * Configuration options for the Iceberg REST Catalog client.\n */\nexport interface IcebergRestCatalogOptions {\n  /** Base URL of the Iceberg REST Catalog API */\n  baseUrl: string\n  /** Optional catalog name prefix for multi-catalog servers */\n  catalogName?: string\n  /** Authentication configuration */\n  auth?: AuthConfig\n  /** Custom fetch implementation (defaults to globalThis.fetch) */\n  fetch?: typeof fetch\n  /**\n   * Access delegation mechanisms to request from the server.\n   * When specified, the X-Iceberg-Access-Delegation header will be sent\n   * with supported operations (createTable, loadTable).\n   *\n   * @example ['vended-credentials']\n   * @example ['vended-credentials', 'remote-signing']\n   */\n  accessDelegation?: AccessDelegation[]\n}\n\n/**\n * Client for interacting with an Apache Iceberg REST Catalog.\n *\n * This class provides methods for managing namespaces and tables in an Iceberg catalog.\n * It handles authentication, request formatting, and error handling automatically.\n *\n * @example\n * ```typescript\n * const catalog = new IcebergRestCatalog({\n *   baseUrl: 'https://my-catalog.example.com/iceberg/v1',\n *   auth: { type: 'bearer', token: process.env.ICEBERG_TOKEN }\n * });\n *\n * // Create a namespace\n * await catalog.createNamespace({ namespace: ['analytics'] });\n *\n * // Create a table\n * await catalog.createTable(\n *   { namespace: ['analytics'] },\n *   {\n *     name: 'events',\n *     schema: { type: 'struct', fields: [...] }\n *   }\n * );\n * ```\n */\nexport class IcebergRestCatalog {\n  private readonly client: HttpClient\n  private readonly namespaceOps: NamespaceOperations\n  private readonly tableOps: TableOperations\n  private readonly accessDelegation?: string\n\n  /**\n   * Creates a new Iceberg REST Catalog client.\n   *\n   * @param options - Configuration options for the catalog client\n   */\n  constructor(options: IcebergRestCatalogOptions) {\n    let prefix = 'v1'\n    if (options.catalogName) {\n      prefix += `/${options.catalogName}`\n    }\n\n    const baseUrl = options.baseUrl.endsWith('/') ? options.baseUrl : `${options.baseUrl}/`\n\n    this.client = createFetchClient({\n      baseUrl,\n      auth: options.auth,\n      fetchImpl: options.fetch,\n    })\n\n    // Format accessDelegation as comma-separated string per spec\n    this.accessDelegation = options.accessDelegation?.join(',')\n\n    this.namespaceOps = new NamespaceOperations(this.client, prefix)\n    this.tableOps = new TableOperations(this.client, prefix, this.accessDelegation)\n  }\n\n  /**\n   * Lists all namespaces in the catalog.\n   *\n   * @param parent - Optional parent namespace to list children under\n   * @returns Array of namespace identifiers\n   *\n   * @example\n   * ```typescript\n   * // List all top-level namespaces\n   * const namespaces = await catalog.listNamespaces();\n   *\n   * // List namespaces under a parent\n   * const children = await catalog.listNamespaces({ namespace: ['analytics'] });\n   * ```\n   */\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    return this.namespaceOps.listNamespaces(parent)\n  }\n\n  /**\n   * Creates a new namespace in the catalog.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespace(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * console.log(response.namespace); // ['analytics']\n   * console.log(response.properties); // { owner: 'data-team', ... }\n   * ```\n   */\n  async createNamespace(id: NamespaceIdentifier, metadata?: NamespaceMetadata): Promise<CreateNamespaceResponse> {\n    return this.namespaceOps.createNamespace(id, metadata)\n  }\n\n  /**\n   * Drops a namespace from the catalog.\n   *\n   * The namespace must be empty (contain no tables) before it can be dropped.\n   *\n   * @param id - Namespace identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropNamespace({ namespace: ['analytics'] });\n   * ```\n   */\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.namespaceOps.dropNamespace(id)\n  }\n\n  /**\n   * Loads metadata for a namespace.\n   *\n   * @param id - Namespace identifier to load\n   * @returns Namespace metadata including properties\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadNamespaceMetadata({ namespace: ['analytics'] });\n   * console.log(metadata.properties);\n   * ```\n   */\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    return this.namespaceOps.loadNamespaceMetadata(id)\n  }\n\n  /**\n   * Lists all tables in a namespace.\n   *\n   * @param namespace - Namespace identifier to list tables from\n   * @returns Array of table identifiers\n   *\n   * @example\n   * ```typescript\n   * const tables = await catalog.listTables({ namespace: ['analytics'] });\n   * console.log(tables); // [{ namespace: ['analytics'], name: 'events' }, ...]\n   * ```\n   */\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    return this.tableOps.listTables(namespace)\n  }\n\n  /**\n   * Creates a new table in the catalog.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTable(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: [\n   *         { source_id: 2, field_id: 1000, name: 'ts_day', transform: 'day' }\n   *       ]\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTable(namespace, request)\n  }\n\n  /**\n   * Updates an existing table's metadata.\n   *\n   * Can update the schema, partition spec, or properties of a table.\n   *\n   * @param id - Table identifier to update\n   * @param request - Update request with fields to modify\n   * @returns Response containing the metadata location and updated table metadata\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.updateTable(\n   *   { namespace: ['analytics'], name: 'events' },\n   *   {\n   *     properties: { 'read.split.target-size': '134217728' }\n   *   }\n   * );\n   * console.log(response['metadata-location']); // s3://...\n   * console.log(response.metadata); // TableMetadata object\n   * ```\n   */\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    return this.tableOps.updateTable(id, request)\n  }\n\n  /**\n   * Drops a table from the catalog.\n   *\n   * @param id - Table identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropTable({ namespace: ['analytics'], name: 'events' });\n   * ```\n   */\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.tableOps.dropTable(id, options)\n  }\n\n  /**\n   * Loads metadata for a table.\n   *\n   * @param id - Table identifier to load\n   * @returns Table metadata including schema, partition spec, location, etc.\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadTable({ namespace: ['analytics'], name: 'events' });\n   * console.log(metadata.schema);\n   * console.log(metadata.location);\n   * ```\n   */\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    return this.tableOps.loadTable(id)\n  }\n\n  /**\n   * Checks if a namespace exists in the catalog.\n   *\n   * @param id - Namespace identifier to check\n   * @returns True if the namespace exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.namespaceExists({ namespace: ['analytics'] });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    return this.namespaceOps.namespaceExists(id)\n  }\n\n  /**\n   * Checks if a table exists in the catalog.\n   *\n   * @param id - Table identifier to check\n   * @returns True if the table exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.tableExists({ namespace: ['analytics'], name: 'events' });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    return this.tableOps.tableExists(id)\n  }\n\n  /**\n   * Creates a namespace if it does not exist.\n   *\n   * If the namespace already exists, returns void. If created, returns the response.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties, or void if it already exists\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespaceIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * if (response) {\n   *   console.log('Created:', response.namespace);\n   * } else {\n   *   console.log('Already exists');\n   * }\n   * ```\n   */\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    return this.namespaceOps.createNamespaceIfNotExists(id, metadata)\n  }\n\n  /**\n   * Creates a table if it does not exist.\n   *\n   * If the table already exists, returns its metadata instead.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created or existing table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTableIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTableIfNotExists(namespace, request)\n  }\n}\n","import { isStorageError, StorageError, StorageUnknownError } from '../lib/errors'\nimport { Fetch, get, head, post, put, remove } from '../lib/fetch'\nimport { recursiveToCamel, resolveFetch } from '../lib/helpers'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected bucketId?: string\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    this.url = url\n    this.headers = headers\n    this.bucketId = bucketId\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return {\n        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    try {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return {\n        data: { path: cleanPath, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { data: { signedUrl: url.toString(), path, token }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data: { path: data.Key }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      data = { signedUrl }\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return {\n        data: data.map((datum: { signedURL: string }) => ({\n          ...datum,\n          signedUrl: datum.signedURL\n            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n            : null,\n        })),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n        headers: this.headers,\n        noResolveJson: true,\n      })\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: recursiveToCamel(data) as Camelize<FileObjectV2>, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...options }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","import SupabaseClient from './SupabaseClient'\nimport type { SupabaseClientOptions } from './lib/types'\n\nexport * from '@supabase/auth-js'\nexport type { User as AuthUser, Session as AuthSession } from '@supabase/auth-js'\nexport {\n  type PostgrestResponse,\n  type PostgrestSingleResponse,\n  type PostgrestMaybeSingleResponse,\n  PostgrestError,\n} from '@supabase/postgrest-js'\nexport {\n  FunctionsHttpError,\n  FunctionsFetchError,\n  FunctionsRelayError,\n  FunctionsError,\n  type FunctionInvokeOptions,\n  FunctionRegion,\n} from '@supabase/functions-js'\nexport * from '@supabase/realtime-js'\nexport { default as SupabaseClient } from './SupabaseClient'\nexport type {\n  SupabaseClientOptions,\n  QueryResult,\n  QueryData,\n  QueryError,\n  DatabaseWithoutInternals,\n} from './lib/types'\n\n/**\n * Creates a new Supabase Client.\n *\n * @example\n * ```ts\n * import { createClient } from '@supabase/supabase-js'\n *\n * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n * const { data, error } = await supabase.from('profiles').select('*')\n * ```\n */\nexport const createClient = <\n  Database = any,\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName>\n): SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName> => {\n  return new SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName>(\n    supabaseUrl,\n    supabaseKey,\n    options\n  )\n}\n\n// Check for Node.js <= 18 deprecation\nfunction shouldShowDeprecationWarning(): boolean {\n  // Skip in browser environments\n  if (typeof window !== 'undefined') {\n    return false\n  }\n\n  // Skip if process is not available (e.g., Edge Runtime)\n  if (typeof process === 'undefined') {\n    return false\n  }\n\n  // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n  const processVersion = (process as any)['version']\n  if (processVersion === undefined || processVersion === null) {\n    return false\n  }\n\n  const versionMatch = processVersion.match(/^v(\\d+)\\./)\n  if (!versionMatch) {\n    return false\n  }\n\n  const majorVersion = parseInt(versionMatch[1], 10)\n  return majorVersion <= 18\n}\n\nif (shouldShowDeprecationWarning()) {\n  console.warn(\n    `  Node.js 18 and below are deprecated and will no longer be supported in future versions of @supabase/supabase-js. ` +\n      `Please upgrade to Node.js 20 or later. ` +\n      `For more information, visit: https://github.com/orgs/supabase/discussions/37217`\n  )\n}\n","import PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport { JsonPathToAccessor, JsonPathToType } from './select-query-parser/utils'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\n\ntype FilterOperator =\n  | 'eq'\n  | 'neq'\n  | 'gt'\n  | 'gte'\n  | 'lt'\n  | 'lte'\n  | 'like'\n  | 'ilike'\n  | 'is'\n  | 'isdistinct'\n  | 'in'\n  | 'cs'\n  | 'cd'\n  | 'sl'\n  | 'sr'\n  | 'nxl'\n  | 'nxr'\n  | 'adj'\n  | 'ov'\n  | 'fts'\n  | 'plfts'\n  | 'phfts'\n  | 'wfts'\n  | 'match'\n  | 'imatch'\n\nexport type IsStringOperator<Path extends string> = Path extends `${string}->>${string}`\n  ? true\n  : false\n\nconst PostgrestReservedCharsRegexp = new RegExp('[,()]')\n\n// Match relationship filters with `table.column` syntax and resolve underlying\n// column value. If not matched, fallback to generic type.\n// TODO: Validate the relationship itself ala select-query-parser. Currently we\n// assume that all tables have valid relationships to each other, despite\n// nonexistent foreign keys.\ntype ResolveFilterValue<\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  ColumnName extends string,\n> = ColumnName extends `${infer RelationshipTable}.${infer Remainder}`\n  ? Remainder extends `${infer _}.${infer _}`\n    ? ResolveFilterValue<Schema, Row, Remainder>\n    : ResolveFilterRelationshipValue<Schema, RelationshipTable, Remainder>\n  : ColumnName extends keyof Row\n    ? Row[ColumnName]\n    : // If the column selection is a jsonpath like `data->value` or `data->>value` we attempt to match\n      // the expected type with the parsed custom json type\n      IsStringOperator<ColumnName> extends true\n      ? string\n      : JsonPathToType<Row, JsonPathToAccessor<ColumnName>> extends infer JsonPathValue\n        ? JsonPathValue extends never\n          ? never\n          : JsonPathValue\n        : never\n\ntype ResolveFilterRelationshipValue<\n  Schema extends GenericSchema,\n  RelationshipTable extends string,\n  RelationshipColumn extends string,\n> = Schema['Tables'] & Schema['Views'] extends infer TablesAndViews\n  ? RelationshipTable extends keyof TablesAndViews\n    ? 'Row' extends keyof TablesAndViews[RelationshipTable]\n      ? RelationshipColumn extends keyof TablesAndViews[RelationshipTable]['Row']\n        ? TablesAndViews[RelationshipTable]['Row'][RelationshipColumn]\n        : unknown\n      : unknown\n    : unknown\n  : never\n\nexport type InvalidMethodError<S extends string> = { Error: S }\n\nexport default class PostgrestFilterBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestTransformBuilder<\n  ClientOptions,\n  Schema,\n  Row,\n  Result,\n  RelationName,\n  Relationships,\n  Method\n> {\n  /**\n   * Match only rows where `column` is equal to `value`.\n   *\n   * To check if the value of `column` is NULL, you should use `.is()` instead.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  eq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? NonNullable<unknown>\n      : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n        // type resolution error\n        ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? NonNullable<ResolvedFilterValue>\n        : // We should never enter this case as all the branches are covered above\n          never\n  ): this {\n    this.url.searchParams.append(column, `eq.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is not equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  neq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `neq.${value}`)\n    return this\n  }\n\n  gt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gt.${value}`)\n    return this\n  }\n\n  gte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gte.${value}`)\n    return this\n  }\n\n  lt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lt.${value}`)\n    return this\n  }\n\n  lte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lte.${value}`)\n    return this\n  }\n\n  like<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  like(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  like(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `like.${pattern}`)\n    return this\n  }\n\n  likeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  likeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilike<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  ilike(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  ilike(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `ilike.${pattern}`)\n    return this\n  }\n\n  ilikeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilikeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  regexMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-sensitively (using the `~` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `match.${pattern}`)\n    return this\n  }\n\n  regexIMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexIMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-insensitively (using the `~*` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexIMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `imatch.${pattern}`)\n    return this\n  }\n\n  is<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: Row[ColumnName] & (boolean | null)\n  ): this\n  is(column: string, value: boolean | null): this\n  /**\n   * Match only rows where `column` IS `value`.\n   *\n   * For non-boolean columns, this is only relevant for checking if the value of\n   * `column` is NULL by setting `value` to `null`.\n   *\n   * For boolean columns, you can also set `value` to `true` or `false` and it\n   * will behave the same way as `.eq()`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  is(column: string, value: boolean | null): this {\n    this.url.searchParams.append(column, `is.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` IS DISTINCT FROM `value`.\n   *\n   * Unlike `.neq()`, this treats `NULL` as a comparable value. Two `NULL` values\n   * are considered equal (not distinct), and comparing `NULL` with any non-NULL\n   * value returns true (distinct).\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  isDistinct<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `isdistinct.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  in<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n          // type resolution error\n          ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : // We should never enter this case as all the branches are covered above\n            never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `in.(${cleanedValues})`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is NOT included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  notIn<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `not.in.(${cleanedValues})`)\n    return this\n  }\n\n  contains<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * `column` contains every element appearing in `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n      // keep it simple and accept a string\n      this.url.searchParams.append(column, `cs.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cs.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  containedBy<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * every element appearing in `column` is contained by `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `cd.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cd.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  rangeGt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is greater than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sr.${range}`)\n    return this\n  }\n\n  rangeGte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or greater than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxl.${range}`)\n    return this\n  }\n\n  rangeLt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is less than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sl.${range}`)\n    return this\n  }\n\n  rangeLte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or less than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxr.${range}`)\n    return this\n  }\n\n  rangeAdjacent<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeAdjacent(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where `column` is\n   * mutually exclusive to `range` and there can be no element between the two\n   * ranges.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeAdjacent(column: string, range: string): this {\n    this.url.searchParams.append(column, `adj.${range}`)\n    return this\n  }\n\n  overlaps<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]>\n  ): this\n  overlaps(column: string, value: string | readonly unknown[]): this\n  /**\n   * Only relevant for array and range columns. Match only rows where\n   * `column` and `value` have an element in common.\n   *\n   * @param column - The array or range column to filter on\n   * @param value - The array or range value to filter with\n   */\n  overlaps(column: string, value: string | readonly unknown[]): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `ov.${value}`)\n    } else {\n      // array\n      this.url.searchParams.append(column, `ov.{${value.join(',')}}`)\n    }\n    return this\n  }\n\n  textSearch<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  textSearch(\n    column: string,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  /**\n   * Only relevant for text and tsvector columns. Match only rows where\n   * `column` matches the query string in `query`.\n   *\n   * @param column - The text or tsvector column to filter on\n   * @param query - The query text to match with\n   * @param options - Named parameters\n   * @param options.config - The text search configuration to use\n   * @param options.type - Change how the `query` text is interpreted\n   */\n  textSearch(\n    column: string,\n    query: string,\n    { config, type }: { config?: string; type?: 'plain' | 'phrase' | 'websearch' } = {}\n  ): this {\n    let typePart = ''\n    if (type === 'plain') {\n      typePart = 'pl'\n    } else if (type === 'phrase') {\n      typePart = 'ph'\n    } else if (type === 'websearch') {\n      typePart = 'w'\n    }\n    const configPart = config === undefined ? '' : `(${config})`\n    this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`)\n    return this\n  }\n\n  match<ColumnName extends string & keyof Row>(query: Record<ColumnName, Row[ColumnName]>): this\n  match(query: Record<string, unknown>): this\n  /**\n   * Match only rows where each column in `query` keys is equal to its\n   * associated value. Shorthand for multiple `.eq()`s.\n   *\n   * @param query - The object to filter with, with column names as keys mapped\n   * to their filter values\n   */\n  match(query: Record<string, unknown>): this {\n    Object.entries(query).forEach(([column, value]) => {\n      this.url.searchParams.append(column, `eq.${value}`)\n    })\n    return this\n  }\n\n  not<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: FilterOperator,\n    value: Row[ColumnName]\n  ): this\n  not(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which doesn't satisfy the filter.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to be negated to filter with, following\n   * PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  not(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `not.${operator}.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows which satisfy at least one of the filters.\n   *\n   * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure it's properly sanitized.\n   *\n   * It's currently not possible to do an `.or()` filter across multiple tables.\n   *\n   * @param filters - The filters to use, following PostgREST syntax\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to filter on referenced tables\n   * instead of the parent table\n   * @param options.foreignTable - Deprecated, use `referencedTable` instead\n   */\n  or(\n    filters: string,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.or` : 'or'\n    this.url.searchParams.append(key, `(${filters})`)\n    return this\n  }\n\n  filter<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: `${'' | 'not.'}${FilterOperator}`,\n    value: unknown\n  ): this\n  filter(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which satisfy the filter. This is an escape hatch - you\n   * should use the specific filter methods wherever possible.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to filter with, following PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  filter(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `${operator}.${value}`)\n    return this\n  }\n}\n","export interface NamespaceIdentifier {\n  namespace: string[]\n}\n\nexport interface NamespaceMetadata {\n  properties: Record<string, string>\n}\n\nexport interface TableIdentifier {\n  namespace: string[]\n  name: string\n}\n\n/**\n * Primitive types in Iceberg - all represented as strings.\n * Parameterized types use string format: decimal(precision,scale) and fixed[length]\n *\n * Note: The OpenAPI spec defines PrimitiveType as `type: string`, so any string is valid.\n * We include known types for autocomplete, plus a catch-all for flexibility.\n */\nexport type PrimitiveType =\n  | 'boolean'\n  | 'int'\n  | 'long'\n  | 'float'\n  | 'double'\n  | 'string'\n  | 'timestamp'\n  | 'date'\n  | 'time'\n  | 'timestamptz'\n  | 'uuid'\n  | 'binary'\n  | `decimal(${number},${number})`\n  | `fixed[${number}]`\n  | (string & {}) // catch-all for any format (e.g., \"decimal(10, 2)\" with spaces) and future types\n\n/**\n * Regex patterns for parsing parameterized types.\n * These allow flexible whitespace matching.\n */\nconst DECIMAL_REGEX = /^decimal\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)$/\nconst FIXED_REGEX = /^fixed\\s*\\[\\s*(\\d+)\\s*\\]$/\n\n/**\n * Parse a decimal type string into its components.\n * Handles any whitespace formatting (e.g., \"decimal(10,2)\", \"decimal(10, 2)\", \"decimal( 10 , 2 )\").\n *\n * @param type - The type string to parse\n * @returns Object with precision and scale, or null if not a valid decimal type\n */\nexport function parseDecimalType(type: string): { precision: number; scale: number } | null {\n  const match = type.match(DECIMAL_REGEX)\n  if (!match) return null\n  return {\n    precision: parseInt(match[1], 10),\n    scale: parseInt(match[2], 10),\n  }\n}\n\n/**\n * Parse a fixed type string into its length.\n * Handles any whitespace formatting (e.g., \"fixed[16]\", \"fixed[ 16 ]\").\n *\n * @param type - The type string to parse\n * @returns Object with length, or null if not a valid fixed type\n */\nexport function parseFixedType(type: string): { length: number } | null {\n  const match = type.match(FIXED_REGEX)\n  if (!match) return null\n  return {\n    length: parseInt(match[1], 10),\n  }\n}\n\n/**\n * Check if a type string is a decimal type.\n */\nexport function isDecimalType(type: string): boolean {\n  return DECIMAL_REGEX.test(type)\n}\n\n/**\n * Check if a type string is a fixed type.\n */\nexport function isFixedType(type: string): boolean {\n  return FIXED_REGEX.test(type)\n}\n\n/**\n * Compare two Iceberg type strings for equality, ignoring whitespace differences.\n * This is useful when comparing types from user input vs catalog responses,\n * as catalogs may normalize whitespace differently.\n *\n * @param a - First type string\n * @param b - Second type string\n * @returns true if the types are equivalent\n */\nexport function typesEqual(a: string, b: string): boolean {\n  // For decimal types, compare parsed values\n  const decimalA = parseDecimalType(a)\n  const decimalB = parseDecimalType(b)\n  if (decimalA && decimalB) {\n    return decimalA.precision === decimalB.precision && decimalA.scale === decimalB.scale\n  }\n\n  // For fixed types, compare parsed values\n  const fixedA = parseFixedType(a)\n  const fixedB = parseFixedType(b)\n  if (fixedA && fixedB) {\n    return fixedA.length === fixedB.length\n  }\n\n  // For other types, direct string comparison\n  return a === b\n}\n\n/**\n * Struct type - a nested structure containing fields.\n * Used for nested records within a field.\n */\nexport interface StructType {\n  type: 'struct'\n  fields: StructField[]\n}\n\n/**\n * List type - an array of elements.\n */\nexport interface ListType {\n  type: 'list'\n  'element-id': number\n  element: IcebergType\n  'element-required': boolean\n}\n\n/**\n * Map type - a key-value mapping.\n */\nexport interface MapType {\n  type: 'map'\n  'key-id': number\n  key: IcebergType\n  'value-id': number\n  value: IcebergType\n  'value-required': boolean\n}\n\n/**\n * Union of all Iceberg types.\n * Can be a primitive type (string) or a complex type (struct, list, map).\n */\nexport type IcebergType = PrimitiveType | StructType | ListType | MapType\n\n/**\n * Primitive type values for default values.\n * Represents the possible values for initial-default and write-default.\n */\nexport type PrimitiveTypeValue = boolean | number | string\n\n/**\n * A field within a struct (used in nested StructType).\n */\nexport interface StructField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\n/**\n * A field within a table schema (top-level).\n * Equivalent to StructField but kept for backwards compatibility.\n */\nexport interface TableField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\nexport interface TableSchema {\n  type: 'struct'\n  fields: TableField[]\n  'schema-id'?: number\n  'identifier-field-ids'?: number[]\n}\n\nexport interface PartitionField {\n  source_id: number\n  field_id: number\n  name: string\n  transform: string\n}\n\nexport interface PartitionSpec {\n  'spec-id': number\n  fields: PartitionField[]\n}\n\nexport interface SortField {\n  source_id: number\n  transform: string\n  direction: 'asc' | 'desc'\n  null_order: 'nulls-first' | 'nulls-last'\n}\n\nexport interface SortOrder {\n  'order-id': number\n  fields: SortField[]\n}\n\nexport interface CreateTableRequest {\n  name: string\n  schema: TableSchema\n  'partition-spec'?: PartitionSpec\n  'write-order'?: SortOrder\n  properties?: Record<string, string>\n  'stage-create'?: boolean\n}\n\nexport interface UpdateTableRequest {\n  schema?: TableSchema\n  'partition-spec'?: PartitionSpec\n  properties?: Record<string, string>\n}\n\nexport interface DropTableRequest {\n  purge?: boolean\n}\n\nexport interface TableMetadata {\n  name?: string\n  location: string\n  schemas: TableSchema[]\n  'current-schema-id': number\n  'partition-specs': PartitionSpec[]\n  'default-spec-id'?: number\n  'sort-orders': SortOrder[]\n  'default-sort-order-id'?: number\n  properties: Record<string, string>\n  'metadata-location'?: string\n  'current-snapshot-id'?: number\n  snapshots?: unknown[]\n  'snapshot-log'?: unknown[]\n  'metadata-log'?: unknown[]\n  refs?: Record<string, unknown>\n  'last-updated-ms'?: number\n  'last-column-id'?: number\n  'last-sequence-number'?: number\n  'table-uuid'?: string\n  'format-version'?: number\n  'last-partition-id'?: number\n}\n\nexport interface CreateNamespaceRequest {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface CreateNamespaceResponse {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface GetNamespaceResponse {\n  namespace: string[]\n  properties: Record<string, string>\n}\n\nexport interface ListNamespacesResponse {\n  namespaces: string[][]\n  'next-page-token'?: string\n}\n\nexport interface ListTablesResponse {\n  identifiers: TableIdentifier[]\n  'next-page-token'?: string\n}\n\nexport interface LoadTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n  config?: Record<string, string>\n}\n\nexport interface CommitTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n}\n\n/**\n * Gets the current (active) schema from table metadata.\n *\n * @param metadata - Table metadata containing schemas array and current-schema-id\n * @returns The current table schema, or undefined if not found\n */\nexport function getCurrentSchema(metadata: TableMetadata): TableSchema | undefined {\n  return metadata.schemas.find((s) => s['schema-id'] === metadata['current-schema-id'])\n}\n","import PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport {\n  ClientServerOptions,\n  Fetch,\n  GenericSchema,\n  GenericTable,\n  GenericView,\n} from './types/common/common'\n\nexport default class PostgrestQueryBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Relation extends GenericTable | GenericView,\n  RelationName = unknown,\n  Relationships = Relation extends { Relationships: infer R } ? R : unknown,\n> {\n  url: URL\n  headers: Headers\n  schema?: string\n  signal?: AbortSignal\n  fetch?: Fetch\n\n  /**\n   * Creates a query builder scoped to a Postgres table or view.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const query = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: { apikey: 'public-anon-key' } }\n   * )\n   * ```\n   */\n  constructor(\n    url: URL,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: string\n      fetch?: Fetch\n    }\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schema = schema\n    this.fetch = fetch\n  }\n\n  /**\n   * Perform a SELECT query on the table or view.\n   *\n   * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n   *\n   * @param options - Named parameters\n   *\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   *\n   * @param options.count - Count algorithm to use to count rows in the table or view.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  select<\n    Query extends string = '*',\n    ResultOne = GetResult<\n      Schema,\n      Relation['Row'],\n      RelationName,\n      Relationships,\n      Query,\n      ClientOptions\n    >,\n  >(\n    columns?: Query,\n    options?: {\n      head?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    ResultOne[],\n    RelationName,\n    Relationships,\n    'GET'\n  > {\n    const { head = false, count } = options ?? {}\n\n    const method = head ? 'HEAD' : 'GET'\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk inserts.\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an INSERT into the table or view.\n   *\n   * By default, inserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to insert. Pass an object to insert a single row\n   * or an array to insert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count inserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. Only applies for bulk\n   * inserts.\n   */\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      count,\n      defaultToNull = true,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', `missing=default`)\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk upserts.\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n    /**\n   * Perform an UPSERT on the table or view. Depending on the column(s) passed\n   * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n   * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n   * exist, or if it does exist, perform an alternative action depending on\n   * `ignoreDuplicates`.\n   *\n   * By default, upserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to upsert with. Pass an object to upsert a\n   * single row or an array to upsert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n   * duplicate rows are determined. Two rows are duplicates if all the\n   * `onConflict` columns are equal.\n   *\n   * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n   * `false`, duplicate rows are merged with existing rows.\n   *\n   * @param options.count - Count algorithm to use to count upserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. This only applies when\n   * inserting new rows, not when merging with existing rows under\n   * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n   *\n   * @example Upsert a single row using a unique key\n   * ```ts\n   * // Upserting a single row, overwriting based on the 'username' unique column\n   * const { data, error } = await supabase\n   *   .from('users')\n   *   .upsert({ username: 'supabot' }, { onConflict: 'username' })\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     { id: 4, message: 'bar', username: 'supabot' }\n   * //   ],\n   * //   error: null\n   * // }\n   * ```\n   *\n   * @example Upsert with conflict resolution and exact row counting\n   * ```ts\n   * // Upserting and returning exact count\n   * const { data, error, count } = await supabase\n   *   .from('users')\n   *   .upsert(\n   *     {\n   *       id: 3,\n   *       message: 'foo',\n   *       username: 'supabot'\n   *     },\n   *     {\n   *       onConflict: 'username',\n   *       count: 'exact'\n   *     }\n   *   )\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     {\n   * //       id: 42,\n   * //       handle: \"saoirse\",\n   * //       display_name: \"Saoirse\"\n   * //     }\n   * //   ],\n   * //   count: 1,\n   * //   error: null\n   * // }\n   * ```\n   */\n\n\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      onConflict,\n      ignoreDuplicates = false,\n      count,\n      defaultToNull = true,\n    }: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    this.headers.append('Prefer', `resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`)\n\n    if (onConflict !== undefined) this.url.searchParams.set('on_conflict', onConflict)\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', 'missing=default')\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform an UPDATE on the table or view.\n   *\n   * By default, updated rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param values - The values to update with\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count updated rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  update<Row extends Relation extends { Update: unknown } ? Relation['Update'] : never>(\n    values: Row,\n    {\n      count,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'PATCH'\n  > {\n    const method = 'PATCH'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform a DELETE on the table or view.\n   *\n   * By default, deleted rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count deleted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  delete({\n    count,\n  }: {\n    count?: 'exact' | 'planned' | 'estimated'\n  } = {}): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'DELETE'\n  > {\n    const method = 'DELETE'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","import PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { Fetch, GenericSchema, ClientServerOptions } from './types/common/common'\nimport { GetRpcFunctionFilterBuilderByArgs } from './types/common/rpc'\n\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nexport default class PostgrestClient<\n  Database = any,\n  ClientOptions extends ClientServerOptions = Database extends {\n    __InternalSupabase: infer I extends ClientServerOptions\n  }\n    ? I\n    : {},\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = 'public' extends keyof Omit<\n    Database,\n    '__InternalSupabase'\n  >\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  Schema extends GenericSchema = Omit<\n    Database,\n    '__InternalSupabase'\n  >[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : any,\n> {\n  url: string\n  headers: Headers\n  schemaName?: SchemaName\n  fetch?: Fetch\n\n  // TODO: Add back shouldThrowOnError once we figure out the typings\n  /**\n   * Creates a PostgREST client.\n   *\n   * @param url - URL of the PostgREST endpoint\n   * @param options - Named parameters\n   * @param options.headers - Custom headers\n   * @param options.schema - Postgres schema to switch to\n   * @param options.fetch - Custom fetch\n   * @example\n   * ```ts\n   * import PostgrestClient from '@supabase/postgrest-js'\n   *\n   * const postgrest = new PostgrestClient('https://xyzcompany.supabase.co/rest/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   schema: 'public',\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: SchemaName\n      fetch?: Fetch\n    } = {}\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schemaName = schema\n    this.fetch = fetch\n  }\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any, any> {\n    if (!relation || typeof relation !== 'string' || relation.trim() === '') {\n      throw new Error('Invalid relation name: relation must be a non-empty string.')\n    }\n\n    const url = new URL(`${this.url}/${relation}`)\n    return new PostgrestQueryBuilder(url, {\n      headers: new Headers(this.headers),\n      schema: this.schemaName,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return new PostgrestClient(this.url, {\n      headers: this.headers,\n      schema,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @example\n   * ```ts\n   * // For cross-schema functions where type inference fails, use overrideTypes:\n   * const { data } = await supabase\n   *   .schema('schema_b')\n   *   .rpc('function_a', {})\n   *   .overrideTypes<{ id: string; user_id: string }[]>()\n   * ```\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    {\n      head = false,\n      get = false,\n      count,\n    }: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    let method: 'HEAD' | 'GET' | 'POST'\n    const url = new URL(`${this.url}/rpc/${fn}`)\n    let body: unknown | undefined\n    if (head || get) {\n      method = head ? 'HEAD' : 'GET'\n      Object.entries(args)\n        // params with undefined value needs to be filtered out, otherwise it'll\n        // show up as `?param=undefined`\n        .filter(([_, value]) => value !== undefined)\n        // array values need special syntax\n        .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n        .forEach(([name, value]) => {\n          url.searchParams.append(name, value)\n        })\n    } else {\n      method = 'POST'\n      body = args\n    }\n\n    const headers = new Headers(this.headers)\n    if (count) {\n      headers.set('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schemaName,\n      body,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.89.0'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, put, remove } from '../lib/fetch'\nimport { resolveFetch } from '../lib/helpers'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    this.url = baseUrl.href.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      const data = await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket/${id}/empty`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","// Always update wrapper.mjs when updating this file.\nimport PostgrestClient from './PostgrestClient'\nimport PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestError from './PostgrestError'\n\nexport {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport type {\n  PostgrestResponse,\n  PostgrestResponseFailure,\n  PostgrestResponseSuccess,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from './types/types'\nexport type { ClientServerOptions as PostgrestClientOptions } from './types/common/common'\n// https://github.com/supabase/postgrest-js/issues/551\n// To be replaced with a helper type that only uses public types\nexport type { GetResult as UnstableGetResult } from './select-query-parser/result'\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, remove } from '../lib/fetch'\nimport { isValidBucketName, resolveFetch } from '../lib/helpers'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * @alpha\n   *\n   * Enable throwing errors instead of returning them in the response\n   * When enabled, failed operations will throw instead of returning { data: null, error }\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns This instance for method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      const data = await get(this.fetch, url, { headers: this.headers })\n\n      return { data: data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { version } from '../version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n  'Content-Type': 'application/json',\n}\n","/**\n * Base error class for all Storage Vectors errors\n */\nexport class StorageVectorsError extends Error {\n  protected __isStorageVectorsError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageVectorsError'\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return typeof error === 'object' && error !== null && '__isStorageVectorsError' in error\n}\n\n/**\n * API error returned from S3 Vectors service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageVectorsApiError extends StorageVectorsError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageVectorsApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageVectorsUnknownError extends StorageVectorsError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageVectorsUnknownError'\n    this.originalError = originalError\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageVectorsApiError, StorageVectorsUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { VectorFetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n * @property headers - Custom HTTP headers\n * @property noResolveJson - If true, return raw Response instead of parsing JSON\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg || err.message || err.error_description || err.error || JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to StorageVectors error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const status = (error as any).status || 500\n    const responseError = error as any\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageVectorsApiError(_getErrorMessage(err), status, statusCode))\n        })\n        .catch(() => {\n          // If JSON parsing fails, create an ApiError with the HTTP status code\n          const statusCode = status + ''\n          const message = responseError.statusText || `HTTP ${status} error`\n          reject(new StorageVectorsApiError(message, status, statusCode))\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageVectorsApiError(message, status, statusCode))\n    }\n  } else {\n    reject(new StorageVectorsUnknownError(_getErrorMessage(error), error))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        // Handle empty responses (204, empty body)\n        const contentType = result.headers.get('content-type')\n        if (!contentType || !contentType.includes('application/json')) {\n          return {}\n        }\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\n/**\n * Performs a GET request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\n/**\n * Performs a POST request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\n/**\n * Performs a PUT request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\n/**\n * Performs a DELETE request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from './types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.vectors.length < 1 || options.vectors.length > 500) {\n        throw new Error('Vector batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    try {\n      // Validate segment configuration\n      if (options.segmentCount !== undefined) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) {\n          throw new Error('segmentCount must be between 1 and 16')\n        }\n        if (options.segmentIndex !== undefined) {\n          if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n            throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n          }\n        }\n      }\n\n      const data = await post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.keys.length < 1 || options.keys.length > 500) {\n        throw new Error('Keys batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from './fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from './types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/fetch'\nimport { StorageVectorsClient } from './lib/vectors'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"names":["DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions","DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions","resolveFetch","resolveResponse","result: Record<string, any>","isPlainObject","count: number | null","res","this","fetch","DEFAULT_AUTH_OPTIONS","DEFAULT_REALTIME_OPTIONS","DEFAULT_GLOBAL_OPTIONS","result: Required<SupabaseClientOptions<SchemaName>>","DEFAULT_DB_OPTIONS","handleError","_getErrorMessage","_getRequestParams","params: { [k: string]: any }","namespaceToPath","_handleRequest","supabaseUrl: string","supabaseKey: string","post","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","SupabaseStorageClient","DEFAULT_FILE_OPTIONS: FileOptions","headers: Record<string, string>","_queryString: string[]","params: string[]","DEFAULT_HEADERS","method: 'HEAD' | 'GET' | 'POST'","body: unknown | undefined","params: Record<string, string>"],"mappings":"yEEKA,EAAA,cAA4C,kBAkB9B,CAAA,CAA2E,OAC/E,EAAA,OAAA,OACD,IAAA,CAAA,sBACA,OAAA,CAAA,EAAkB,OAAA,MAClB,IAAA,CAAO,EAAA,IAAQ,MACf,IAAA,CAAO,EAAQ,IAAA,GGjBM,EAA9B,MAQA,YAwBc,CAAA,CAUT,cA5BO,kBAAA,EAAqB,OA6BxB,MAAA,CAAA,EAAiB,MAAA,UACX,EAAQ,GAAA,MACd,OAAA,CAAU,IAAI,QAAA,EAAgB,OAAA,OAC9B,MAAA,CAAS,EAAQ,MAAA,MACjB,IAAA,CAAO,EAAA,IAAQ,CACpB,CEnCA,GAAA,CFmCK,kBAAA,CAAA,MAAA,CAAA,EAAqB,EAAQ,kBAAA,GAAA,GAAA,IAC7B,IAD6B,EAC7B,CAAS,EAAQ,MAAA,EADkC,IAEnD,GG5CH,MH0CgC,IG1ChC,CAAA,AH0CgC,MG1ChC,CAAA,EH4CmB,EAAQ,aAAA,GAAA,EAEzB,CAFyB,CAEjB,KAAA,CACV,CAH2B,GAG3B,CAAK,KAAA,CAAQ,EAAQ,CAHuB,IAGvB,CAErB,IAAA,CAAK,GALsB,EAKtB,CAAQ,EALc,kBAesC,aAC9D,kBAAA,EAAqB,EACnB,IAAA,CAMT,UAAU,CAAA,CAAc,CAAA,CAAA,aACjB,OAAA,CAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ,MACnC,OAAA,CAAA,GAAA,CAAY,EAAM,MAAM,OAU7B,CAAA,CAQA,CAAA,CACkC,WAEd,GG1DH,GAAA,IH0Db,AAA2B,IAA3B,CAAK,MAAA,GAEE,CAAC,MAAO,OAAO,CAAC,QAAA,CAAS,IAAA,CAAK,MAAA,CAAO,CAC9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,iBAAkB,IAAA,CAAK,MAAA,CAAO,MAE1C,OAAA,CAAQ,GAAA,CAAI,kBAAmB,IAAA,CAAK,MAAA,CAAO,EAE9B,aAAX,MAAA,EAAoC,OAC3C,EAD2B,IAAA,CAAK,MAAA,EAChC,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,eAAgB,mBAAmB,CAMtD,IAAA,EADe,AACf,CGpEQ,MAAA,CAAA,KAAA,EHoER,IAAiB,CAAK,CGnEP,EAAA,CHmEW,QAAA,GAAA,CACxB,OAAA,IAAA,CAAA,MAAA,CACA,QAAS,IAAA,CAAK,IGlEN,GAAA,CHmER,KAAM,KAAA,SAAK,CAAU,IAAA,CAAK,IAAA,CAAK,CGlET,AHmEtB,OAAQ,IAAA,CAAK,MAAA,GACZ,IAAA,CAAA,MAAY,oBACT,EAAQ,KACZ,EAAW,KACPM,EAAuB,KACvB,EAASC,EAAI,MAAA,CACb,EAAaA,EAAI,UAAA,IAEjBA,EAAI,EAAA,CAAI,IACNC,AAAgB,WAAX,MAAA,CAAmB,CAC1B,IAAM,EAAO,MAAMD,EAAI,IAAA,EAAM,AAChB,MAAT,IAGF,EADwC,KACjC,MAAP,EADSC,EAAK,EIxIkC,KJwIlC,CAAQ,GAAA,CAAI,SAAS,EAGnCA,EAAK,CIzIb,MJyIa,CAAQ,GAAA,CAAI,YAAS,CAAA,MAAA,EAC1BA,CI1I2C,CJ0ItC,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,KAAA,EAAA,EAAE,IAAF,IAAE,CAAS,iBAAX,KAAA,YAAW,CAAkC,CAEhE,CAAP,CAEO,AAFP,KAEY,KAAA,CAAM,IAItB,IAAM,EAAA,MAAA,CAAA,EAAcA,EAAK,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,KAAA,EAAA,EAAE,IAAF,CAAE,CAAM,qBAAR,KAAA,QAA0C,CACxF,EAAA,MAAA,CAAA,EAAqBD,EAAI,OAAA,CAAQ,GAAA,CAAI,gBAAA,CAAgB,CAAA,KAAA,EAAA,EAAE,IAAF,CAAE,CAAM,IAAI,CAC7D,GAAe,GAAgB,EAAa,MAAA,AADK,CACI,EACvD,EAAA,AAFmD,EAE3C,SAAS,CAAA,CAAa,GAAA,CAAG,CAK/BC,EAAK,aAAA,EAAiC,QAAhBA,CK/ID,CL+IM,MAAA,EAAoB,MAAM,KI7IrD,EAAA,CJ6I6D,KAC3D,AADgE,CACpE,CAAS,AAAT,MAAS,CAAS,GAAG,GAGjB,KAAM,WACN,QAAA,CAAA,gBAAA,EAA4B,EAAK,MAAA,CAAO,uDAAA,CAAA,MAClC,KACN,QAAS,kEAGH,OACC,MACI,kBAEb,EADyB,IAAhB,EAAK,MAAA,CACP,CAAA,CAAK,EAAA,CAEL,GKhJR,OLmJE,aACcD,EAAAA,IAAAA,OAGjB,EAAA,KAAa,KAAA,CAAM,EK9IX,OLiJE,OAAA,CAAQ,IAAUA,AAAe,EAAnB,GAAwB,GAApBA,MAAAA,KACnB,EAAE,GK/IX,OLiJW,MACI,cAET,CAEa,MAAfA,EAAI,MAAA,EAAkB,UACf,MACI,yBAGF,CAAA,CACV,IAID,GAASC,EAAK,aAAA,EAAA,CAAA,MAAA,GAAwB,MAAxB,CAAA,EAAiB,EAAO,OAAA,CAAA,CAAA,IAAA,CAAA,EAAA,EAAS,QAAA,CAAS,SAAA,CAAS,GAAE,SAE5D,YAIP,EKnJN,CLmJeA,EAAK,kBAAA,CAChB,MAAM,IAAI,EAAe,CKpJM,ELgKnC,MAR0B,OACxB,SAEA,QACA,oBACA,YAKA,AAAC,IAAA,CAAK,kBAAA,GACR,EAAM,EAAI,KAAA,CAAA,AAAO,SKvJoB,eL2J/B,EAAe,GAGb,EAAA,MAAA,EAAA,KAAA,EAAQ,EAAY,KAAA,CAC1B,GAAI,EAAO,CK3JT,AL4JA,IAAM,EAAA,OAAA,EAAA,MAAA,EAAA,KAAA,EAAe,EAAO,OAAA,EAAA,EAAW,EAAX,CACtB,EAAA,KADsB,CACtB,CAAA,EAAA,MAAA,EAAA,KAAA,EADsB,AACV,EAAO,GADG,CACH,EAAA,EAAQ,EAAR,MAEV,EAFU,IAEV,CAAA,EAAA,EACC,CAAA,GADD,EAAA,CAFU,IAEV,CAFU,CAEP,EAAY,IAAA,EAAA,EAAQ,aAAa,EAAA,QAAA,EAAA,KAAA,EAAI,EAAY,OAAA;AACnD;AAAA,WAAA,EAAA,MAAA,CAAA,EAAA,MAAA,EAAA,KAAA,EAAkB,EAAO,IAAA,EAAA,EAAQ,EAAR,MAAgB,EAAhB,AAAgB,EAAI,EAAA,CAAA,AADM,KAGjE,GAAA,CAAA,EAAA,AAFuC,EAElB,EAAU,CAAA,AAFQ,CAER,IOpNtC,cPsNS,EAAO,KAAA,CACT,GAAA,GAAgB,CAAA;AAAA,EAAK,EAAM,KAAA,CAAA,CAAA,QAExB,yBAEU,EAAY,KAAA,EAAA,EAAS,EAAT,OAGtB,CACL,AAJ2B,MAIpB,SACI,CAAA,EAAA,IALgB,EAKhB,CAAA,EALgB,AAKhB,MAAA,EAAA,KAAA,EAAG,EAAY,IAAA,EAAA,EAAQ,EAAR,QAAA,GAAqB,EAAA,QAAA,EAAA,KAAA,EAAI,AAAzB,EAAqC,GAArC,CAAqB,GAAgB,CAAA,CAAA,CAC7D,EAD6C,MACpC,EACT,KAAM,EAFuC,CAG7C,IAH6C,CAGvC,IAER,KAAM,KACN,MAAO,KACP,EUnPD,KVmPS,aACI,SAKP,IAAA,CAAA,EAAkB,GAS/B,QAT0C,CAS1C,QAMS,IAAA,CA6BT,eAAA,QAaS,IAAA,KY1TX,cAQU,EAUR,OAIE,CAAA,CAAA,KAeI,CA7B0C,EA6BjC,IACW,SAAA,EAAW,CAAX,EAAW,CAAA,CAChC,IADqB,CACrB,CAAM,GAAG,CACT,GAAA,CAAA,AAAK,EAFgB,CAGhB,GADM,CAFU,CAGX,IAAA,CAAK,EAAE,EAAI,CAAC,EACZ,KAAP,CAAA,OAGA,GAAS,CAAA,CAAA,EAEJ,IAER,IAAA,CAAK,gBACH,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,SAAU,QAC/B,OAAA,CAAQ,MAAA,CAAO,SAAA,yBACb,IAAA,CFsCH,MEkBJ,CAAA,CACA,WACE,GAAY,CAAA,YACZ,CAAA,cACA,CAAA,iBACA,EAAkB,CAAA,CAAA,CAMhB,CAAA,CAAE,CACA,KACA,EAAM,EAAkB,CAAA,EAAG,EAAgB,MAAA,CAAA,CAAU,UACrC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,IAAI,WAE/C,GAAA,CAAI,YAAA,CAAa,GAAA,CACpB,EAAA,CAAA,EACG,EAAgB,CAAA,EAAG,EAAc,CAAA,CAAA,CAAK,GAAA,EAAK,EAAO,CAAA,EAAG,EAAY,MAAQ,OAAA,EAC3D,KAAA,IAAf,EAA2B,GAAK,EAAa,cAAgB,aAAA,CAAA,CAEhE,CACM,IAAA,CAaT,MACE,CAAA,CACA,CACE,CE/DI,aAAA,iBFgEJ,EAAA,CAAA,CAAA,CACuD,CAAA,CAAA,CACnD,CACN,IAAA,EAAY,KAA2B,IAApB,EAAkC,QAAU,CAAA,EAAG,CEjEpD,CFiEoE,MAAA,CAAA,aAC7E,GAAA,CAAI,EEjEP,UAAA,CFiEoB,GAAA,CAAI,EAAK,CAAA,EAAG,EAAA,CAAA,CAAQ,CACnC,IAAA,CAkBT,MACE,CAAA,CACA,CAAA,CACA,cACE,CAAA,iBACA,EAAkB,CAAA,CAAA,CACqC,CAAA,CAAE,CACrD,CACN,IAAM,EACJ,KAA2B,IAApB,EAAkC,SAAW,CAAA,EAAG,EAAgB,OAAA,CAAA,CACnE,EAAW,KAA2B,IAApB,EAAkC,QAAU,CAAA,EAAG,EAAgB,MAAA,CAAA,iBAC9E,YAAA,CAAa,GAAA,CAAA,EAAe,CAAA,EAAG,EAAA,CAAA,CAAO,UAEtC,YAAA,CAAa,GAAA,CAAI,EAAU,CAAA,EAAG,EAAK,EAAO,EAAA,CAAA,CAAI,CAChD,IAAA,aAQG,CAAA,CAA2B,aAChC,MAAA,CAAS,EACP,IAAA,CAST,QAGE,aACK,OAAA,CAAQ,GAAA,CAAI,SAAU,oCAAoC,CACxD,IAAA,CAST,aAEuD,OAGjC,oBAClB,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAU,CH2GI,kBG3Ge,CAE9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAU,0CAExB,aAAA,CAAA,CAAA,OAOP,KAA+C,aACxC,OAAA,CAAQ,GAAA,CAAI,SAAU,YACpB,IAAA,CAMT,SAAoE,aAC7D,OAAA,CAAQ,GAAA,CAAI,SAAU,6BA6B7B,QAAQ,SACN,GAAU,CAAA,SACV,EAAU,EAAA,UACV,GAAW,CAAA,SACX,GAAU,CAAA,KACV,GAAM,CAAA,QACN,EAAS,MAAA,CAAA,CAQP,CAAA,CAAE,CAAE,OACN,IAAM,EAAU,CACd,EAAU,UAAY,KACtB,EAAU,UAAY,KACtB,EAAW,WAAa,KACxB,EAAU,UAAY,KACtB,EAAM,MAAQ,KACf,CACE,MAAA,CAAO,QAAQ,CACf,IAAA,CAAK,IAAI,CAEN,EAAA,OAAA,EAAe,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,EAAI,GAAJ,QAAA,oBAC1C,EAD0C,KAAA,AAC1C,CAAQ,GAAA,CACX,SACA,CAAA,2BAAA,EAA8B,EAAO,OAAA,EAAS,EAAa,WAAA,EAAa,EAAQ,CAAA,CAAA,CACjF,CAEQ,IAAA,mBAYT,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,IIvP9B,WJwPO,IAAA,CAST,SAQE,QACO,IAAA,CAiBT,YAAY,CAAA,CAKiE,aACtE,OAAA,CAAQ,MAAA,CAAO,SAAU,kBAAkB,MAC3C,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,aAAA,EAAgB,EAAA,CAAA,CAAQ,CAC/C,IAAA,OK3UL,EAA+B,AAAI,OAAO,QAAQ,CA2CxD,IAAqB,EAArB,OA3CM,OAmDI,EAiBR,GACE,CAAA,AArEE,CAsEF,CAAA,CAQM,CAEN,OADA,IAAA,CAAK,GAAA,CAAI,AApBX,YAoBW,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAST,IACE,CAAA,CACA,CAAA,CAKM,CAEN,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,GAAG,CAAA,CAAgB,CAAA,CAAsB,CAEvC,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CACnD,IAAO,CAWT,IAAI,CAAA,CAAgB,CAAA,CAAsB,aACnC,GAAA,CAAA,YAAA,CAAiB,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,GAAA,CAAA,CAAmB,CAAA,CAAsB,QACvC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,KAWL,CAAA,CAAgB,CAAA,CAAsB,aACnC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,KAAK,CAAA,CAAgB,CAAA,CAAuB,aACrC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,KAAA,EAAQ,EAAA,CAAA,CAAU,CAChD,IAAA,CAcT,UAAU,CAAA,CAAgB,CAAA,CAAmC,CAE3D,YADK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAClE,IAAA,CAcT,UAAU,CAAA,CAAgB,CAAA,CAAmC,CAE3D,gBADS,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAClE,IAAA,CAWT,MAAA,CAAA,CAAsB,CAAA,CAAuB,aACtC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,MAAA,EAAS,EAAA,CAAA,CAAU,CACjD,IAAA,CAcT,WAAW,CAAA,CAAgB,CAAA,CAAmC,CAE5D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,IF+HK,CACvB,CAAA,CEhIyB,EAAQ,CAAA,YAAA,EAAe,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACnE,IAAA,CAcT,WAAW,CAAA,CAAgB,CAAA,CAAmC,CAE5D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,YAAA,EAAe,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACnE,IAAA,CAYT,WAAW,CAAA,CCvOF,CAAA,CDuOyC,CAEhD,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,MAAA,EAAS,EAAA,CAAA,CAAU,CACjD,IAAA,CAYT,YAAY,CAAA,CAAgB,CC9NrB,CD8N4C,CAEjD,CChO4B,CAAA,KD+N5B,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,OAAA,EAAU,EAAA,CAAA,CAAU,CACzD,IAAO,CAoBT,GAAG,CAAA,CAAgB,CAAA,CAA6B,QAC9C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,KAC5C,CAaT,WACE,CAAA,CACA,CAAA,CAKM,CAEN,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAA,CAAA,CAAQ,CACpD,IAAA,CAST,GACE,CAAA,CACA,CAAA,CAUM,CACN,IAAM,EAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,IACtC,GAD6C,AAC7C,CAAK,AADyC,AAC9C,GAGC,AAAiB,GAHP,OAGN,OAAO,GAAkB,EAA6B,IAAA,CAAK,EAAE,CAAE,AAAO,CAAP,AAAO,CAAA,EAAI,EAAE,CAAA,CAAA,CACpE,CAAA,EAAG,EAAA,CAAA,EAEhB,IAAA,CAAK,IAAI,CAEZ,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAc,CAAA,CAAA,CAAG,CACtD,IAAA,CAST,MACE,CAAA,CACA,CAAA,CAOM,CACN,IAAM,EAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,IACtC,GAD6C,AAC7C,CAD8C,AAC9C,AAAK,GAGa,AAAjB,GAHU,OAGN,OAAO,GAAkB,EAA6B,IAAA,CAAK,EAAE,CAAE,AAAO,CAAP,AAAO,CAAA,EAAI,EAAE,CAAA,CAAA,CACpE,CAAA,EAAG,EAAA,CAAA,EACf,IAAA,CACI,IAAI,CAEZ,OADA,IAAA,CAAA,GAAA,CAAS,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,QAAA,EAAW,EAAc,CAAA,CAAA,CAAG,CAC1D,IAAA,CAeT,SAAS,CAAA,CAAgB,CAAA,CAAoE,CAY3F,MAXqB,SAGnB,CAHE,OAAO,EAGT,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC1C,MAAM,OAAA,CAAQ,GAEvB,GAF6B,CAE7B,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,GAAM,CAAA,CAAG,CAAH,AAE3D,IAAA,CAeT,YAAY,CAAA,CAAgB,CAAA,CAAoE,CAW9F,MAVqB,SAEnB,CAFE,OAAO,EAET,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC1C,MAAM,OAAA,CAAQ,GAEvB,GAF6B,CAE7B,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,GAAM,CAAA,CAAG,CAAH,AAE3D,IAAA,CAYT,QAAQ,CAAA,CAAgB,CAAA,CAAqB,CAE3C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAaT,SAAS,CAAA,CAAA,CAAA,CAAA,CAEP,OADA,IAAA,CAAK,GAAA,CAAA,YAAA,CAAiB,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAYT,QAAQ,CAAA,CAAgB,CAAA,CAAqB,CAE3C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAaT,SAAS,CAAA,CAAgB,CAAA,CAAqB,CAE5C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAaT,cAAc,CAAA,CAAgB,CAAA,CAAqB,CAEjD,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAeT,SAAS,CAAA,CAAgB,CAAA,CAA0C,CAQjE,MAPqB,SAEnB,CAFE,OAAO,EAET,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAGnD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAE1D,IAAA,CAuBT,WACE,CAAA,CACA,CAAA,CACA,QAAE,CAAA,CAAQ,MAAA,CAAA,CAAuE,CAAA,CAAE,CAC7E,CACN,IAAI,EAAW,GACF,UAAT,EAAS,EACA,KACO,SAClB,EADS,EACT,EAAW,KACO,YAClB,EADS,GACT,GAAW,GAAA,EAEb,IAAM,EAAwB,KAAA,IAAX,EAAW,GAAiB,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAE1D,OADA,IAAA,CAAA,GAAA,CAAS,YAAA,CAAa,MAAA,CAAO,EAAA,CAAA,EAAW,EAAA,GAAA,EAAc,EAAW,CAAA,EAAA,EAAA,CAAA,EACjE,IAAA,CAYF,MAAM,CAAA,CAAsC,CAI1C,OAHA,OAAO,OAAA,CAAQ,GAAO,GAAD,IAAC,CAAA,CAAS,CAAC,EAAQ,EAAA,IACtC,CADiD,GACjD,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,GAE9C,IAAA,CAsBT,IAAI,CAAA,CAAgB,CAAA,CAAkB,CAAA,CAAsB,CAE1D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAS,CAAA,EAAG,EAAA,CAAA,CAAQ,CACzD,IAAA,CAkBT,GACE,CAAA,CACA,cACE,CAAA,iBACA,EAAkB,CAAA,CAAA,CACqC,CAAA,CAAE,CACrD,CACN,IAAM,EAAM,EAAkB,CAAA,EAAG,EAAgB,GAAA,CAAA,CAAO,KAExD,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAK,CAAA,CAAA,EAAI,EAAQ,CAAA,CAAA,CAAG,CAC1C,IAAA,CAsBT,OAAO,CAAA,CAAgB,CAAA,CAAkB,CAAA,CAAsB,CAE7D,gBADS,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,EAAG,EAAS,CAAA,EAAG,EAAA,CAAA,CAAQ,CACrD,IAAA,GElqBU,EAArB,MAME,AAoBA,YACE,CAAA,CACA,SACE,EAAU,CAAA,CAAE,QACZ,CAAA,CACA,MAAA,CAAA,CAAA,CAMF,CACA,IAAA,CAAK,GAAA,CAAM,EACX,IAAA,CAAK,OAAA,CAAU,IAAI,QAAQ,GAC3B,IAAA,CADmC,AAC9B,MAAA,CAAS,EACd,IAAA,CAAK,KAAA,CAAQC,EAwBf,OAAA,CAWE,CACA,CAAA,CAYA,UACQ,GAAO,CAAA,OAAO,CAAA,CAAA,OAAU,EAAA,EAAW,CAAA,CAAE,CAIzC,GAAS,EACP,EAAA,OAAkB,EAAA,EAAW,GAAA,CAAA,CAChC,GADqB,EACrB,CAAM,GAAG,CACT,CAFqB,EAErB,CAAA,AAAK,GACA,GADM,EACD,CAHW,GAGX,CAAK,CAHM,GAGA,CAAC,EACZ,IAEC,CAFR,CAAA,GAGA,CADE,IACF,EAAS,CAAC,CAAA,EAEL,IAER,IAAA,CAAK,GAAG,CAOX,OANA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,SAAU,GAEhC,GACF,GAAA,CAAA,CAAK,IAH4C,GAG5C,CAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAG1C,IAAI,EAAuB,CAChC,OAtBa,EAAO,OAAS,MAuB7B,IAAK,IAAA,CAAK,GAAA,CACV,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,IAAA,CAAK,MAAA,CACb,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CA2DJ,OACE,CAAA,CACA,OACE,CAAA,eACA,GAAgB,CAAA,CAAA,CAId,CAAA,CAAE,CASN,OAUA,GAPI,GACF,GAAA,CAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAE7C,AAAC,GACH,IAAA,CAAK,MAAL,CAAK,CAAQ,MAAA,CAAO,SAAU,CAAA,eAAA,CAAA,CAAkB,CAG9C,MAAM,OAAA,CAAQ,GAAS,CACzB,GADuB,CACjB,EAAU,EAAO,MAAA,CAAA,CAAQ,EAAK,IAAM,EAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,CAAE,EAAE,CAAa,CACrF,GAAI,EAAQ,MAAA,CAAS,EAAG,CACtB,IAAM,EAAgB,CAAC,GAAG,IAAI,IAAI,GAAS,CAAC,GAAA,CAAF,AAAE,AAAK,GAAW,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAAG,CAC1E,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAW,EAAc,IAAA,CAAK,IAAI,CAAC,EAIjE,OAAO,IAAI,EAAuB,CAChC,OAlBa,OAmBb,IAAK,IAAA,CAAK,GAAA,SACD,IAAA,CAAK,OAAA,QACN,IAAA,CAAK,MAAA,CACb,KAAM,EACN,MAAA,MAAA,CAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,MA6HhB,EA7HgB,KA8Hd,CAAA,CACA,SA/Hc,GAgIZ,CAAA,CAhIY,iBAiIZ,GAAmB,CAAA,OACnB,CAAA,eACA,EAAgB,EAAA,CAAA,CAMd,CAAA,CAAE,CASN,OAaA,GAVA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,WAAA,EAAc,EAAmB,SAAW,QAAQ,WAAA,CAAA,CAAa,CAE5E,KAAA,EAAW,EAA1B,GAA0B,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,cAAe,GACnE,GACF,GAAA,CAAA,CAFgF,AAE3E,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAE7C,AAAC,GACH,IAAA,CAAK,MAAL,CAAK,CAAQ,MAAA,CAAO,SAAU,kBAAkB,CAG9C,MAAM,OAAA,CAAQ,GAAS,CACzB,GADuB,CACjB,EAAU,EAAO,MAAA,CAAA,CAAQ,EAAK,IAAM,EAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,CAAE,EAAE,CAAa,CACrF,GAAI,EAAQ,MAAA,CAAS,EAAG,CACtB,IAAM,EAAgB,CAAC,GAAG,IAAI,IAAI,GAAS,CAAC,GAAA,CAAA,AAAF,AAAO,GAAW,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAAG,MACrE,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAW,EAAc,IAAA,CAAK,IAAI,CAAC,EAIjE,OAAO,IAAI,EAAuB,CAChC,OArBa,OAsBb,IAAK,IAAA,CAAK,GAAA,CACV,CJqoB4B,OIroBnB,IAAA,CAAK,OAAA,CACd,OAAA,IAAQ,CAAK,MAAA,MACP,iBACC,EJuoBkB,CACvB,CAAA,CIxoBU,KAAA,EAAA,EAAS,MACtB,EAwBH,OACE,CAAA,CACA,OACE,CAAA,CAAA,CAGE,CAAA,CAAE,CASN,OAMA,OAJI,GACF,GAAA,CAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAG1C,IAAI,EAAuB,CAChC,OANa,QAOb,IAAK,IAAA,CAAK,GAAA,CACV,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,IAAA,CAAK,MAAA,CACb,KAAM,EACN,MAAA,OAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,CAsBJ,EAvBgB,KAuBT,OACL,CAAA,CAAA,CAGE,CAAA,CAAE,AA3BU,CAmCd,IAnCc,GAyCd,OAJI,GACF,GAAA,CAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAG1C,IAAI,EAAuB,CAChC,OANa,SAOb,IAAK,IAAA,CAAK,GAAA,CACV,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,IAAA,CAAK,MAAA,CACb,MAAA,OAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,GCteN,ADqekB,ECrelB,MAAqB,EA6CnB,ODwbgB,KCvbd,ADubc,CCvbd,CA1BF,AA2BE,SACE,EAAU,CAAA,CAAE,QACZ,CAAA,CACA,MAAA,CAAA,CAAA,CAKE,CAAA,CAAE,CACN,CACA,IAAA,CAAK,GAAA,CAAM,EACX,IAAA,CAAK,OAAA,CAAU,IAAI,QAAQ,GAC3B,IAAA,CADmC,AAC9B,UAAA,CAAa,EAClB,IAAA,CAAK,KAAA,CAAQA,EAcf,KAAK,CAAA,CAA0E,CAC7E,GAAI,CAAC,GAAgC,UAApB,OAAO,GAA6C,GACnE,EAD+C,EAAS,IAAA,EAAM,CAC9D,MAAM,AAAI,MAAM,8DAA8D,CAIhF,OAAO,IAAI,EADC,IAAI,IAAI,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAA,CAAA,CAAW,CACR,CACpC,QAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ,CAClC,OAAQ,IAAA,CAAA,UAAA,CACR,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CAUJ,OACE,CAAA,CAMA,CACA,OAAO,IAAI,EAAgB,IAAA,CAAK,GAAA,CAAK,CACnC,QAAS,IAAA,CAAK,OAAA,QACd,EACA,MAAO,IAAA,CAAK,KAAA,OA6Cd,CAAA,CACA,EAAA,CAAA,CAAe,CACf,MACE,GAAO,CAAA,KACP,GAAM,CAAA,OACN,CAAA,CAAA,CAKE,CAAA,CAAE,CASN,WACIuB,EAEAC,EADE,EAAM,IAAI,IAAI,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,KAAA,EAAO,EAAA,CAAA,CAAK,CAExC,GAAQ,GACV,EAAS,AADM,EACC,OAAS,MACzB,OAAO,OAAA,CAAQ,GAGZ,EAHiB,IAGjB,CAAA,CAAQ,CAAC,EAAG,EAAA,GAAqB,KAAA,EAAU,EAApB,GAEvB,GAAA,CAAA,CAAK,CAAC,EAAM,EAAA,GAAW,CAAC,EAAM,MAAM,OAAA,CAAQ,GAAS,CAAA,CAAA,CAAH,CAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAK,CAAA,EAAG,EAAA,CAAA,CAAQ,CAAC,CAC1F,OAAA,CAAA,CAAS,CAAC,EAAM,EAAA,IACf,CAD0B,CACtB,YAAA,CAAa,MAAA,CAAO,EAAM,IAC9B,EADoC,CAGxC,EAAS,OACT,EAAO,GAGT,IAAM,EAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ,CAKzC,OAJI,GACF,EAAQ,CAAR,EAAQ,CAAI,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAGlC,IAAI,EAAuB,QAChC,MACA,UACA,EACA,OAAQ,IAAA,CAAK,UAAA,MACb,EACA,MAAA,OAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,GADY,gBAAA,KAAA,WzB9ML,EAAN,UAAM,IAAqB,KAAA,CAAM,AAOtC,WAAA,CACE,CAAA,CACA,CAAA,CAMA,MACA,CAAM,GACN,IADa,AACb,CAAK,AADQ,IACR,CAAO,eACZ,IAAA,CAAK,MAAA,CAAS,ACvBA,EDuBK,EAAL,IAAK,CACnB,IAAA,CAAK,WAAA,CAAc,EAAK,WAAA,CACxB,CExB8C,GFwB9C,CAAK,WAAA,CAAc,EAAK,EAAL,SAAK,CACxB,IAAA,CAAK,OAAA,CAAU,EAAK,EAAL,KAAK,CAGpB,IAAA,CAAK,oBAAA,CACkB,6BAAA,GAArB,EAAK,EAAL,SAAK,EACJ,CAAC,IAAK,GAAA,CAAK,GAAG,CAAA,CAAE,QAAA,CAAS,EAAK,MAAM,CAAA,EAAK,EAAK,WAAA,EAAa,QAAA,CAAS,aAAa,CAAA,IAAM,CAC5F,CAKA,EAN4F,QAM5F,EAAsB,QACG,GAAA,GAAhB,IAAA,CAAA,MAAK,CAMd,YAAsB,CACpB,OAAuB,GAAA,GAAhB,IAAA,CAAK,MAAA,AACd,0BAKmC,CACjC,OAAA,AAAuB,GAAA,GAAvB,IAAA,CAAY,MAAA,AACd,GQrDF,eAAe,EAAA,CAAiB,EAAoD,OAClF,AAAK,GAAa,QAAiB,CAAtB,EAAK,IAAA,CAIA,aAAT,IAAA,CACA,CAAE,cAAe,CAAA,OAAA,EAAU,EAAA,EAAA,GAAU,CAAA,CAAA,CAAG,CAG/B,UAAU,GAAnB,IAAA,CACA,CAAE,CAAC,EAAK,EAAL,EAAS,CAAA,CAAG,EAAK,KAAA,CAAM,CAGjB,UAAU,CAAxB,EAAK,IAAA,CACA,MAAM,EAAK,UAAA,GAGb,CAAA,CAAC,CAfN,CAAA,CAgBJ,UEXS,EAAA,CAAgB,EACvB,OAAO,EAAU,IAAA,CAAK,YAGX,EAAN,kBAEc,CAAA,CACA,EAAiB,EAAA,CAClC,CAFiB,IAAA,CAAA,MAAA,CAAA,EACA,IAAA,CAAA,MAAA,CAAA,wBAGE,CAA8D,CACjF,IAAM,EAAQ,EAAS,CAAjB,AAAmB,MAAA,CAAQ,EAAgB,EAAO,SAAS,CAAA,CAAE,CAAI,KAAA,CAAA,CAQvE,ILgJQ,EKhJD,CANU,MAAM,CDCG,CACxB,ECFqB,CAAK,MAAA,CAAO,OAAA,CAAgC,QACzD,MACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,WAAA,CAAA,CACpB,OAAA,EAAA,EAGc,IAAA,CAAK,UAAA,CAAW,GAAA,CAAI,AAAC,EAAA,EAAQ,CAAR,AAAU,SAAA,CAAW,EAAA,CAAG,CAC/D,AADiE,CAAA,AAGjE,MAAM,gBACJ,CAAA,CAAA,CACA,CACkC,CAClC,IAAA,EAAwC,CACtC,UAAW,EAAA,AAAG,SAAA,CACd,WAAA,GAAsB,UAAA,EASxB,MAAO,CANU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAiC,CAClE,OAAQ,mBACC,CAAK,MAAM,CAAA,WAAA,CAAA,MACd,KAGQ,IAAA,OAGZ,cAAc,CAAA,CAAwC,CAC1D,MAAA,IAAM,CAAK,MAAA,CAAO,OAAA,CAAc,CAC9B,OAAQ,SACR,IAAA,CAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,EAAgB,EAAA,AAAG,SAAS,CAAC,CAA7B,AAA6B,CAAA,GAIpE,MAAA,sBAA4B,CAAA,CAAqD,CAM/E,MAAO,YACO,CANG,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA8B,CAC/D,MAAA,CAAQ,KAAA,CACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAA,EAA+B,EAAA,AAAG,SAAS,CAAC,CAAA,CAAA,ELoJ7B,AKnJpC,CAAA,CAGsB,IAAA,CAAK,UAAA,CAE9B,CAEA,MAAM,gBAAgB,CAAA,CAAA,IAChB,CAKF,aAJM,IAAA,CAAA,MAAA,CAAA,OAAY,CAAc,CAC9B,MAAA,CAAQ,OACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,EAAgB,EAAA,AAAG,ELuJxB,OKvJiC,CAAC,CAAA,CAAA,IAE3D,CACT,CAAA,EADS,IACA,EAAO,CACd,GAAI,aAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,CAAtB,EAAgB,GAAM,QAClC,CAET,IAFS,GAET,EAEJ,CAEA,MAAA,2BAAA,CACE,CACA,CAAA,CACyC,KAEvC,OAAO,MAAM,IAAA,CAAK,eAAA,CAAgB,EAAA,AAAI,GACxC,KADgD,CACvC,AADuC,EAChC,CACd,EADO,CACH,aAAiB,GAAiC,KAAK,CAAtB,EAAM,GEvDO,EAAqB,CAArB,AAAsB,CFwDtE,MAEF,OAAM,CACR,CACF,GAFU,AKhFZ,SAASd,EAAgB,CAAA,EAA6B,AACpD,OAAO,EAAU,IAAA,CAAK,GAAM,CAAA,GAC9B,CAEO,IAAA,EAAA,IHwCkB,cGtCJ,CAAA,CACA,EAAiB,EAAA,CACjB,CADA,AACA,CACjB,CAHiB,IAAA,CAAA,MAAA,CAAA,EACA,GHyCjB,CAAA,CGzCiB,MAAA,CAAA,EACA,IAAA,CAAA,gBAAA,CAAA,CAChB,CAEH,MAAM,WAAW,CAAA,CAA4D,CAM3E,MAAA,CALiB,MAAM,IAAA,CAAA,MAAK,CAAA,OAAO,CAAA,CACjC,OAAQ,KAAA,CACR,KAAM,CAAA,EAAA,IAAG,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAgB,EAAU,CHqDE,CAAC,OAAA,EGrDO,OAAA,CAAA,CHsDrD,CGrDnB,CAAA,CAEe,IAAA,CAAK,WACvB,AADuB,OAGjB,YAAA,CACJ,CACA,CAAA,CHmD+B,AGlDP,CHkDQ,AGjDhC,IAAM,EAAkC,CAAA,CAAC,CAYzC,OAXI,IAAA,CAAK,gBAAA,EAAkB,CACzB,CAAA,CAAQ,8BAA6B,CAAI,IAAA,CAAK,EHyDpC,cAAA,AGzDoC,EAUzC,CAPU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B,CAC5D,OAAQ,YACF,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAgB,EAAA,OAAA,EAAmB,CAAC,CAAA,OAAA,CAAA,CACvE,KAAM,eAIQ,IAAA,CAAK,QAAA,oBAGL,CAAA,CAAqB,CAA2D,CAChG,IAAM,EAAW,MAAM,AAAjB,IAAiB,CAAK,MAAA,CAAO,OAAA,CAA2B,CAC5D,MDoEkD,CCpE1C,OACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAAA,EAAmB,SAAA,EAAU,GH0FI,KG1FJ,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,CAClF,KAAM,IAGR,MAAO,CACL,oBAAqB,EAAS,IAAA,CAAK,CAAd,mBAAiC,CACtD,QAAA,CAAU,EAAS,IAAA,CAAK,IC3DoE,IAAA,QD+D1F,UAAA,CAAU,CAAqB,CAAA,CAA2C,CAC9E,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc,QACtB,SACR,KAAA,CAAA,EAAS,IAAA,CAAA,MAAW,CAAA,YAAA,EAAeA,EAAgB,EAAA,AAAG,SAAS,EAAC,QAAA,EAAW,EAAA,AAAG,IAAA,CAAA,CAAI,CAClF,MAAO,CAAE,cAAA,CAAgB,OAAO,GAAS,IAAT,CAAS,GAAS,EAAK,GAAA,CAAA,MAIrD,UAAU,CAAA,CAA6C,CAC3D,IAAA,EAAwC,CAAA,CAAC,CAWzC,OAVI,IAAA,CAAK,gBAAA,EAAkB,EACzB,CAAQ,8BAA6B,CAAA,IAAI,CAAK,gBAAA,EASzC,CANU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B,CAC5D,OAAQ,MACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,CCnDK,CACvB,UDkDkB,EAAeA,EAAgB,EAAA,AAAG,SAAS,CAAC,CAAA,CAA7BA,OAA6B,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,cAIpE,IAAA,CAAK,QAAA,AACvB,oBAEkB,CAAuC,KACjD,EAAkC,CAAA,CAAC,CACrC,IAAA,CAAA,gBAAA,EAAuB,EACzB,CAAQ,8BAA6B,CAAI,IAAA,CAAK,gBAAA,EAGhD,GAAI,QACF,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAA,CAChB,OAAQ,OACR,IAAA,CAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,GG9FsD,SH8FtD,EAAeA,EAAgB,EAAA,AAAG,SAAS,CAAC,CAAA,CAA7BA,OAA6B,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,SAClF,IAEK,SACA,EAAO,CACd,EADO,CACH,aAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,CAAtB,EAAgB,GAAM,CACzC,OAAO,CAET,IAFS,GAEH,CACR,CACF,OAEM,uBAAA,CACJ,CACA,CAAA,CACwB,CACxB,GAAI,CG7FkD,AH8FpD,OAAO,MAAA,IAAM,CAAK,WAAA,CAAY,EAAW,EAC3C,CAAA,IADgC,AAAkB,CAAA,CAClD,EAAgB,CACd,GAAI,KAAA,QAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,CAAtB,EAAgB,GAAM,CACzC,OAAO,MAAM,IAAA,CAAK,SAAA,CAAU,CAAE,SAAA,CAAW,EAAU,SAAA,CAAW,IAAA,CAAM,EAAQ,IAAA,CAAM,AAAd,CAAc,AAEpF,OAAM,CACR,IADQ,AI/CC,EAAN,MAAyB,AAW9B,YAAY,CAAA,CAAoC,CAC9C,IAAI,EAAS,IAAA,CACT,EAAQ,WAAA,CDhCe,CCgCF,CACvB,GAAU,CAAA,CAAA,EAAI,EAAQ,WAAW,EAAA,EAGnC,MAAM,EAAU,EAAQ,KAAR,EAAQ,CAAQ,QAAA,CAAS,KAAO,EAAA,KAAA,EAAA,CAAkB,CAAA,EAAG,EAAQ,KAAR,EAAe,CAAA,CAAA,CAAA,CAEpF,IAAA,CAAK,MAAA,CAAS,SXpEF,AAAkB,CAAA,EAInB,AACb,IAAM,EAAU,EAAQ,GAAlB,MAAkB,EAAa,UAAA,CAAW,KAAA,CAEhD,MAAO,CACL,MAAM,OAAA,CAAW,CACf,QAAA,MACA,CAAA,CAAA,MAAA,CACA,MACA,CAAA,SACA,CAAA,CACF,EAA0C,IAClC,EFvCL,AEuCW,QAAA,CFvCF,AACd,CAAA,CACA,CAAA,CACA,CAAA,EACQ,IACF,EAAM,IAAA,IAAQ,EAAM,GAE1B,GAAI,CAF6B,CAAA,AAG/B,GADE,CACF,CADS,EACE,CAAC,EAAK,EAAK,GAAA,AAAK,OAAO,OAAA,CAAQ,GAC1B,IADkC,CAClC,CAAA,EAAW,CAArB,GACF,EAAA,CAAA,WAAI,CAAa,GAAA,CAAI,EAAK,CAAL,EAK3B,EALqC,CAAA,IAKrC,EAAW,QAAA,IEwBc,EAAQ,KAAR,EAAQ,CAAS,EAAM,GACtC,EAD2C,AAC7B,CAD6B,KACvB,EAAiB,CAArC,CAA6C,IAAI,CAAZ,AAAY,CAEjD,EAAM,IAFc,EAEd,EAAc,EAAK,CAAL,OACxB,EACA,QAAS,CACP,GAAA,EAAA,CAAa,cAAA,CAAgB,kBAAA,EAAuB,CAAA,CAAC,CACrD,GAAG,CAAA,CACH,GAAG,CAAA,CACL,aACkB,SAAA,CAAU,GAAQ,KAAA,IAGhC,EAAA,MAAa,EAAI,IAAA,GACjB,EAAA,CAAA,EAAc,OAAA,CAAQ,GAAA,CAAI,iBAAmB,EAAA,EAAI,QAAA,CAAS,kBAAkB,CAAA,MAC3D,EAAA,KAAa,KAAA,CAAM,GAAe,CDiB3D,CCfE,GAAI,CAAA,EAAK,EAAA,CAAI,CACX,IAAM,EAAA,EAAA,EAAoD,KAAA,EAC1D,EAAoB,GAAA,KACpB,OAAM,IAAA,EAAA,GACS,SAAW,CAAA,2BAAA,EAA8B,EAAI,CAAJ,KAAU,CAAA,CAAA,CAChE,CACE,OAAQ,EAAI,CAAJ,KAAI,CACZ,YAAa,GAAa,KAC1B,YAAa,GAAa,IAAA,CAC1B,QAAS,GAGf,CAEA,MAAO,CAAE,MAAA,CAAQ,EAAI,CAAJ,KAAI,CAAQ,OAAA,CAAS,EAAI,CAAJ,MAAI,MAAS,CAAA,CAAgB,AACrE,EADqD,EWsBrB,WAE9B,KAAM,EAAQ,IAAA,CACd,UAAW,EAAQ,KAAR,AAAQ,CACpB,CAAA,CAGD,IAAA,CAAK,gBAAA,CAAmB,EAAQ,KAAR,WAAQ,EAAkB,IAAA,CAAK,GAAG,CAAA,CAE1D,IAAA,CAAK,YAAA,CAAe,IAAI,EAAoB,IAAA,CAAK,MAAA,CAAQ,GACzD,GAD+D,CAC/D,AAD+D,CAC1D,QAAA,CAAW,IAAI,EAAgB,IAAA,CAAK,MAAA,CAAQ,EAAQ,IAAR,AAAQ,CAAK,gBAAgB,CAAA,AAChF,CAAA,MAiBM,eAAe,CAAA,CAA8D,CACjF,OAAO,IAAA,CAAK,YAAA,CAAa,cAAA,CAAe,GAoB1C,GApBgD,CAAA,EAoB1C,gBAAgB,CAAA,CAAyB,CAAA,CAAgE,CAC7G,OAAO,IAAA,CAAK,YAAA,CAAa,eAAA,CAAgB,EAAA,AAAI,GAe/C,KAfuD,CAAA,AAevD,cAAoB,CAAA,CAAA,CAClB,MAAA,IAAM,CAAK,YAAA,CAAa,aAAA,CAAc,EAAE,CAAA,AAe1C,MAAM,sBAAsB,CAAA,CAAqD,CAC/E,OAAO,IAAA,CAAK,YAAA,CAAa,qBAAA,CAAsB,EAAE,CAAA,AAenD,MAAA,WAAiB,CAAA,CAA4D,CL8N7C,AK7N9B,OAAO,IAAA,CAAK,QAAA,CAAS,UAAA,CAAW,EAClC,CAiCA,MAAM,WAAA,CACJ,CAAA,CACA,CAAA,CACwB,CEtIM,AFuI9B,CEtIF,MFsIS,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAW,EAC9C,CAuBA,IAxBmC,AAAkB,CAAA,CAwB/C,WAAA,CAAY,CAAA,CAAqB,CAAA,CAA2D,CAChG,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAI,AAAJ,EACnC,CAYA,IAb8C,CAAA,CAaxC,SAAA,CAAU,CAAA,CAAqB,CAAA,CAA2C,CAC9E,MAAM,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,EAAA,AAAI,EACpC,CAeA,IAhB2C,CAAA,CAgBrC,UAAU,CAAA,CAA6C,aAC/C,QAAA,CAAA,SAAS,CAAU,EAAE,AACnC,CADmC,AAenC,MAAM,gBAAgB,CAAA,CAA2C,CAC/D,CCFiD,MDE1C,IAAA,CAAK,YAAA,CAAa,eAAA,CAAgB,EAAE,AAC7C,CAD6C,AAe7C,MAAM,YAAY,CAAA,CAAuC,CACvD,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EACnC,AADqC,CAyBrC,AAzBqC,MAyB/B,0BAAA,CACJ,CAAA,CACA,CAAA,CACyC,CACzC,OAAO,IAAA,CAAK,YAAA,CAAa,0BAAA,CAA2B,EAAA,AAAI,EAC1D,CA6BA,KA9BkE,CA8B5D,AA9B4D,sBA8B5D,CACJ,CAAA,CACA,CAAA,CACwB,CACxB,OAAO,IAAA,CAAK,QAAA,CAAS,sBAAA,CAAuB,EAAW,EACzD,GlB5XW,EkB2XmC,AAAkB,AlB3XlE,CkB2XkE,alB3XhC,MAAM,AAGtC,YAAA,CAAA,CAA6B,CAC3B,KAAA,CAAA,CDsBY,OCzBJ,gBAAA,EAAmB,CD2BR,CCvBnB,IAAA,CAAK,IAAA,CAAO,0BAIA,EAAe,CAAA,EAAuC,MAC5C,UAAjB,OAAO,GAAgC,OAAV,GAAkB,qBAAsB,MAGjE,EAAb,cAAqC,EAInC,WAJgD,CAIpC,CAAA,CAAiB,CAAA,CAAA,CAAgB,CAAoB,OACzD,QACD,IAAA,CAAO,uBACP,MAAA,CAAA,OACA,UAAA,CAAa,EAGpB,QAAS,EDwBT,KCvBS,CACL,KAAM,IAAA,CAAA,IAAA,CACN,QAAS,IAAA,CAAA,OAAA,CACT,OAAQ,IAAA,CAAK,MAAA,CACb,WAAY,IAAA,CAAK,UAAA,IAKV,EAAb,cAAyC,EAGvC,WAHoD,CAGxC,CAAA,CAAiB,CAAA,CAAwB,OAC7C,QACD,IAAA,CAAO,GKvCA,wBLwCP,aAAA,CAAgB,GKnCH,KCHTjB,EAAAA,AAAgB,GACvB,EACF,CAAQ,GAAG,IAAS,EAApB,CAFwD,AAExD,EAAmC,GAErC,CAAA,CAF0C,EAAR,AAEvB,IAAA,SAAkB,KAAK,AAOH,aACrB,OAAA,CAAA,GACR,OAAO,EAAK,GAAA,CAAK,AAAL,GAAY,EAAiB,GAAG,CAAC,GACpB,YAAhB,OAAA,GAA8B,IAAS,OAAO,GACvD,EAD4D,CAC5D,IAAO,EAGT,IAAME,EAA8B,CAAA,EAMpC,OALA,OAAA,OAAA,CAAe,GAAA,OAAA,CAAA,CAAe,CAAC,EAAA,EAAA,MACd,EAAI,OAAA,CAAQ,gBAAA,AAAkB,GAAM,EAAE,WAAA,EAAa,CAAC,OAAA,CAAQ,QAAS,GAAG,CAAC,EACvE,EAAiB,KAG7B,krCKVT,IAAA,EAA0B,AAA1B,QACE,WAAI,GAAA,EAAA,EAAA,OACA,EACJ,EAAI,iBAAA,GACkB,CADlB,SACH,OAAO,EAAI,KAAA,CAAqB,EAAI,KAAA,CAAA,MAAA,CAAA,EAAQ,EAAI,KAAA,EAAA,IAAA,CAAA,EAAA,EAAO,GAAP,IAAO,GACxD,KAAK,GAD4C,KAAA,CAC5C,CAAU,IAEXW,EAAc,MAClB,EF4DM,EE1DN,CF0DM,IEtDF,aAFQ,MAAMZ,ALlBX,UKoBqB,CAAA,OAAA,EAAA,KAAA,EAAC,EAAS,aAAA,EACpC,EACG,IAAA,EAAM,CACN,IAAA,CAAA,AAAM,IACL,IADa,AACP,EAAS,EAAA,MAAA,EAAgB,IAC/B,EAAA,CAAA,MAAA,EAAA,KAAA,EAAmB,EAAK,UAAA,GAAc,EAAS,KACxC,IAAI,EFuDT,AEvDyBa,EAAiB,GAAM,EAAQ,GFuDvC,GErDpB,KAAA,CAAA,AAAO,IACN,EAAO,IAAI,EAAoBA,EAAiB,GAAM,CAAF,GAAM,CAAC,CAG/D,EAAO,IAAI,EAAoBA,EAAiB,GAAQ,KA8B5D,CA9BkE,CAAC,aA8BpDI,EG9CL,CAAA,CHgDR,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,OAAO,IAAI,QAAA,CAAS,EAAS,WAAW,AACtC,EAAQ,GA7BJF,EAA+B,AA6BtBD,CA7BwB,OA6BN,EA7Bc,QAAA,CAAA,QAAA,KAAA,EAAS,EAAS,OAAA,GAAW,CAAA,CAAE,EAE1E,AAAW,WAAS,CAAC,EAChB,GAGLZ,AAHF,ALrBSA,CKqBT,ALrBSA,AAAiB,IAC5B,GAAqB,QKuBH,ELvBd,KKuBqB,ELvBd,GAAgC,KACzC,EAD+B,EAC/B,MAAO,GAGT,IAAM,EAAY,OAAO,cAAA,CAAe,GACxC,GAD8C,GAC9C,CACiB,AADjB,OAAA,GACiB,IACC,OAAO,SAAA,EACgB,OAArC,OAAO,cAAA,CAAe,EAAe,CAAA,EACvC,CAAA,CAAE,GADgC,IACzB,WAAA,IAAe,CAAA,CAAA,EACxB,CAAA,CAAE,OAAO,QAAA,IAAY,CAAA,CAAA,GKoCuC,GGrDP,GH+B9C,IGxCT,GAAA,CAAA,EAAA,CHwCqB,eAAgB,mCAAuB,EAAS,OAAA,SACrD,KAAK,GGxCF,MAAA,CHwCY,KAAK,QAEpB,EGzCG,KH4DsB,SAhBrC,EAAS,MAAA,CACX,GAAA,EAAO,MAAA,CAAS,EAAQ,MAAA,SAGd,GAYsC,KGrDXc,CHsDlC,AAbkB,IAalB,CAAA,AAAM,CGtDgE,MHuDjE,CAAC,EAAO,EAAA,CAAI,MAAM,wBAClB,EAAS,aAAA,CAAe,CAAA,AAAO,EAC5B,EAAO,IAAA,EAAM,GAErB,IAAA,CAAA,AAAM,GAAA,EAAiB,IACvB,KAAA,CAAA,AAAO,GAAUJ,EAAY,EAAO,EAAQ,MAInD,EAJ2D,CAAC,YAItC,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CGxDyC,SH0DlCK,EAAe,EAAS,MAAO,EAAA,EAAc,WAAW,OAG3CG,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,OACPH,EAAe,AG/DlB,EH+D2B,OAAQ,EAAK,EAAS,CG/DdD,CAAAA,kBHkEnB,EAAA,CAAA,CAEpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,GEAiD,IFCxDC,EAAAA,EAAwB,MAAO,EAAK,EAAS,EAAY,EECZ,GFDiB,aAGjD,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CEJ4C,SFMrCA,EACL,EACA,OAAA,EAAA,EAAA,EAAA,CAAA,EAGK,GAAA,CAAA,EAAA,CACH,eAAe,CAAA,GAEjB,GAIJ,QAHG,OAGmB,EACpB,CAAA,CACA,CGtFY,AHsFZ,CACA,CAAA,CAAA,CAAA,CAAA,CAAA,EAIA,OAAA,EAAsB,EAAS,SAAU,EAAK,EG1FPD,EAAAA,GCrDzC,CDqDyCA,GCrDpB,EAArB,MACE,YACUK,CAAAA,CACAC,CAAAA,CACR,KAFQ,CAAA,UAAA,CAAA,MACA,CAAA,kBAAA,CAAA,EAGV,KAAA,CAAA,CAIE,CDuDU,CCtDoB,CDsDpB,OCrDH,CDsDL,GAAA,CCtDU,OAAA,GAAU,IAAA,CAAK,EAAa,GAG1C,MAAA,SAAiE,IAC3D,cACa,MAAMjB,KAAK,UAAA,EAAA,CAAY,CAGvB,IAAA,CACb,MAAO,YAEF,EAAA,IACHA,KDsDJ,ACtDS,kBAAA,CACP,MAAM,KAGJ,EDmDJ,CAAA,EClDE,MAAO,CAAE,KAAA,WAAY,CDoDxB,QCjDO,OE9BA,OAAO,WAAA,CADnB,IAAqB,EAArB,oBAMYiB,CAAAA,CACR,CAFQ,IAAA,CAAA,UAAA,CAAA,EACA,IAAA,CAAA,kBAAA,CAAA,UAL8B,2BAChC,OAAA,CAAgD,KAOxD,UAAkC,CAChC,OAAO,IAAI,EAAsB,EH4FzB,EG5FyB,CAAK,UAAA,CAAY,IAAA,CAAK,kBAAA,CAAmB,MAI1E,CAAA,CACA,CAAA,CAC8B,QACvB,IAAA,CAAA,UAAA,GAAkB,GHyFrB,CAAA,CGzF0B,EAAa,SAI3C,CAAA,CACyC,CACzC,OAAO,IAAA,CAAK,IHyFH,MAAA,GGzFgB,KAAA,CAAM,GAGjC,QAH4C,AAGpC,CAAA,CAAgE,QAC/D,IAAA,CAAK,UAAA,EAAY,CAAC,OAAA,CAAQ,GAG3B,OAHqC,KAGO,QAC9C,AAAC,IAAA,CAAK,OAAA,EACR,KAAA,CAAK,OAAA,CAAU,IAAA,CAAK,OAAA,EAAA,CAAS,CAExB,IAAA,CAAA,OAAA,OAGK,SAAyC,CACrD,GAAI,CAGF,MAAO,CACL,KAAM,MAAA,CAHO,MAAMjB,KAAK,UAAA,EAAA,CAAY,CAGjB,IAAA,EAAM,CACzB,MAAO,YAEF,EAAO,IACVA,KAAK,CCmCP,iBAAA,CDlCA,MAAM,KAGJ,EAAe,GAAA,MACV,CAAE,KAAM,ECgCjB,2BCtEA,EAAyB,CAC7B,MAAO,CDoFe,GCnFtB,OAAQ,SACA,CACN,OAAQ,aACD,QAILmB,EAAoC,CACxC,aAAc,mBACD,2BACb,QAAQ,OAeW,EAArB,MAOE,YACE,CAAA,CACA,EAAqC,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,oCACK,CAAM,OACN,OAAA,CAAU,OACV,QAAA,CAAW,OACX,KAAA,CAAQzB,EAAAA,iBAQa,aACrB,kBAAA,EAAqB,EACnB,IAAA,OAUK,eACZ,CD4DI,CC3DJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,IACI,CAEF,IADI,EACE,EAAA,EAAA,EAAA,CAAA,EAAe,GAAyB,GAC1C0B,EAAAA,EAAAA,EAAAA,CAAAA,EACCpB,KAAK,OAAA,EACO,SAAX,GAAqB,CAAE,WAAY,OAAO,EAAQ,MAAA,CAAkB,CAAE,EAGtE,EAAW,EAAQ,QAEL,AAFK,AAErB,qBAAO,MAAwB,aAAoB,MAAM,OAChD,QAAA,EACN,MAAA,CAAA,eAAuB,EAAQ,YAAA,EAChC,GACF,EAAK,MAAA,CAAO,WAAYA,KAAK,cAAA,CAAA,YAE1B,CAAO,GAAI,IACa,KADJ,QAChB,OAAO,UAA4B,aAAoB,UAG5D,AAAC,GAFE,CAAA,EAEG,GAAA,CAAA,iBACR,EAAK,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,IAE7C,CAAC,EAAA,GAAK,CAAA,aACpB,EAAK,MAAA,CAAO,WAAYA,KAAK,cAAA,CAAe,QAGvC,CAHgD,CAAC,mBAI7B,CAAA,QAAA,EAAW,EAAQ,YAAA,CAAA,CAAA,kBACtC,CAAkB,EAAQ,WAAA,CAE9B,IACF,CAAA,CAAQ,GAAR,UAAQ,CAAgBA,KAAK,QAAA,CAASA,KAAK,cAAA,CAAe,GAAS,CAAC,EAMzC,aAA1B,OAAO,gBAAkC,aAAgB,gBACzD,GAAwB,UAAhB,OAAO,GAAqB,SAAU,GAAQ,AAAqB,mBAAd,EAAK,IAAA,AAAS,CAAA,EAE9D,CAAC,EAAQ,MAAA,CACvB,EAAA,EAAQ,MAAA,CAAS,MAAA,mBAIjB,EAAa,OAAA,CACf,GAAA,EAAA,EAAA,EAAA,CAAA,EAAe,GAAY,EAAY,QAAA,MAGnC,EAAYA,KAAK,mBAAA,CAAoB,KAAK,AHyGA,AGxGlCA,KAAK,aAAA,CAAc,GAC3B,EAAO,KAD8B,CAC9B,CAAiB,OAAV,EAAkB,EAAMe,CAAAA,CAAAA,CAC1Cf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,EAAA,EAAA,SACE,CAAA,EAAA,OAAA,EAAA,KAAA,EAAa,EAAS,CAAtB,KAAsB,EAAS,CAAE,AAAjC,OAAyC,EAAQ,GAAjD,GAAiD,CAAQ,CAAzD,AAA4D,CAAA,CAAE,EACjE,OAEM,CACL,KAAM,CAAE,KAAM,EAAW,GAAI,EAAK,EAAA,CAAI,SAAA,EAAe,GAAA,EACrD,MAAO,YAEF,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,MAAO,CAAE,KAAM,WAAM,SAGjB,GAgDV,MAAM,OACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,OAAA,IAAA,CAAY,cAAA,CAAe,OAAQ,EAAM,EAAU,GAkCrD,MAAM,GAlC2D,eAmC/D,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,IAAM,EAAYA,KAAK,mBAAA,CAAoB,GACrC,EAD0C,AAClCA,KAAK,aAAA,CAAc,GAE3B,EAAM,IAAI,CAF2B,GAEvBA,KAAK,GAAA,CAAM,CAAA,oBAAA,EAAuB,EAAA,CAAA,CAAQ,CAC9D,EAAI,YAAA,CAAa,GAAA,CAAI,QAAS,GAE9B,GAFoC,AAEhC,CAEF,IADI,EACE,EAAA,EAAA,CAAY,OAAQ,EAAqB,MAAA,EAAW,GAC1D,EAAA,EAAA,EAAA,CAAA,EACKA,KAAK,OAAA,EACL,CAAE,WAAY,OAAO,EAAQ,MAAA,CAAkB,CAAE,EAkBtD,MAfI,AAAgB,oBAAT,MAAwB,aAAoB,MAAM,OAChD,QAAA,EACN,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,CAC3D,EAAK,MAAA,CAAO,GAAI,IACa,KADJ,QAChB,OAAO,UAA4B,aAAoB,SAEhE,CADA,AAD0E,EACnE,CAAA,EACF,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,EAE3D,EAAA,EACA,CAAA,CAAQ,gBAAA,CAAmB,CAAA,QAAA,EAAW,EAAQ,YAAA,CAAA,CAAA,CAC9C,CAAA,CAAQ,eAAA,CAAkB,EAAQ,WAAA,EAK7B,CACL,KAAM,CAAE,KAAM,EAAW,SAAA,CAHd,MAAM,EAAA,KAAS,KAAA,CAAO,EAAI,QAAA,EAAU,CAAE,EAAgB,CAAE,SAAA,EAAS,CAAC,CAGrC,GAAA,QACjC,YAEF,EAAO,IACVA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,SAGjB,GAkCV,MAAA,sBACE,CAAA,CACA,CAAA,CAUA,IACI,CACF,IAAI,EAAQA,KAAK,aAAA,CAAc,GAEzB,EAF8B,AAE9B,EAAA,CAAA,EAAeA,KAAK,OAAA,kBAEtB,EAAS,MAAA,CACX,GAAA,CAAA,CAAQ,WAAA,CAAc,MAAA,EAGxB,IAAM,EAAO,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,oBAAA,EAAsB,EAAA,CAAA,CAClC,CAAA,CAAE,CACF,SAAE,CAAA,CAAS,CACZ,CAEK,EAAM,IAAI,IAAIA,KAAK,GAAA,CAAM,EAAK,GAAA,CAAI,CAElC,EAAQ,EAAI,YAAA,CAAa,GAAA,CAAI,QAAQ,IAEvC,CAAC,EAAA,MACG,IAAI,EAAa,2BAA2B,CAGpD,MAAA,CAAS,KAAM,CAAE,UAAW,EAAI,QAAA,EAAU,MAAE,QAAM,GAAS,MAAO,YAC3D,EAAO,IACVA,KAAK,kBAAA,CACP,MAAM,OAEW,GACjB,MAAO,CAAE,KAAM,WAAM,SAGjB,SAgDJ,OACJ,CAAA,CACA,CAAA,CAWA,CAAA,CAUA,CACA,OAAA,IAAA,CAAY,cAAA,CAAe,MAAO,EAAM,EAAU,GA8BpD,MAAM,GA9B0D,EA+B9D,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CAYF,MAAO,CAAE,KAXI,MAAMe,EAAAA,KACZ,KAAA,CACL,CAAA,EAAGf,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,CACE,SAAUA,KAAK,QAAA,CACf,UAAW,EACX,EE9GG,aAAA,mCF+GgB,EAAS,iBAAA,GAE5B,QAASA,KAAK,OAAA,GAEH,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,SA+BJ,KACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CAYF,MAAO,CAAE,KAAM,CAAE,KAAA,CAXJ,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,CACE,SAAUA,KAAK,QAAA,CACf,UAAW,EACX,eAAgB,EAChB,wBAAA,EAAA,KAAA,EAAmB,EAAS,CAA5B,QAAA,QAA4B,EAE9B,CAAE,CAFA,KAAA,EAEA,KAAA,OAAc,EAAS,CAC1B,CAC2B,GAAA,CAAK,CAAE,MAAA,YAC5B,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAGvB,AAH8B,OAGxB,GAuDV,MAAM,gBACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CACF,IAAI,EAAQA,KAAK,aAAA,CAAc,GAE3B,EAAO,MAAMe,EACff,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAA,EAAA,CAAe,CAAA,EAAA,WACzB,CAAA,EAAA,OAAA,EAAA,KAAA,EAAe,EAAS,CAAxB,QAAwB,AAAxB,EAAoC,CAAE,SAAtC,CAAiD,EAAQ,EAAzD,OAAyD,CAAW,CAAG,CAAA,CAAE,EAC3E,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACD,EAAM,OAAA,EAAA,KAAA,EAAqB,EAAS,CAA9B,OAA8B,CAA9B,CACF,CAAA,UAAA,AADE,GACgC,EADhC,EACW,EAAQ,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACtD,GAGJ,MAAO,CAAE,KADT,EAAO,CAAE,UADS,UAAU,CAAA,EAAGA,KAAK,GAAA,CAAA,EAAM,EAAK,SAAA,CAAA,EAAY,EAAA,CAAA,CAAqB,CAC5D,CACL,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAGvB,CE5EA,MF4EM,GA0CV,MAAM,iBACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,YACA,GAAI,CACF,IAAM,EAAO,MAAMe,EACjBf,EAAK,KAAA,CACL,CAAA,EAAGA,EAAK,GAAA,CAAI,aAAA,EAAeA,EAAK,QAAA,CAAA,CAAA,CAChC,WAAE,QAAW,EAAO,CACpB,CAAE,QAASA,EAAK,OAAA,CAAS,CAC1B,CAEK,EAAA,OAAA,EAAA,KAAA,EAAqB,EAAS,CAA9B,OAA8B,CAA9B,CACF,CAAA,UADE,AACF,EAAa,CAAqB,EADhC,IACmB,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACtD,GACJ,MAAO,CACL,KAAM,EAAK,GAAA,CAAA,AAAK,GAAA,EAAA,EAAA,CAAA,EACX,GAAA,CAAA,EAAA,CACH,UAAW,EAAM,SAAA,CACb,UAAU,CAAA,EAAGA,EAAK,GAAA,CAAA,EAAM,EAAM,SAAA,CAAA,EAAY,EAAA,CAAA,CAAqB,CAC/D,IAAA,GACH,CACH,MAAO,KACR,OACM,EAAO,CACd,GAAIA,EAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAGvB,AAH8B,OAGxB,GA0CV,SACE,CAAA,CACA,CAAA,CACqB,CAErB,IAAM,EADsB,AAA8B,OAA9B,SAAA,EAAA,KAAA,EAAO,EAAS,CAAhB,QAAA,AAAgB,EACH,UADb,KAAA,cAC4C,SACxE,EAA4B,IAAA,CAAK,0BAAA,CAAA,OAAA,EAAA,KAAA,EAA2B,EAAS,CAApC,QAAA,AAAoC,GAAa,CAAA,CAAE,CAAC,CAC/E,EAAA,EAAoC,CADT,AACS,CAAA,EAAI,EADb,AACa,CAAA,CAAwB,KACxD,IAAA,CAAK,aAAA,CAAc,KAAK,KAM/B,IAAI,EALL,IACJ,EAAI,IAAA,CAAK,KAAA,CAAO,CAAA,AAIa,EAJV,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAW,CAAA,EAAG,EAAA,EAAQ,EAAA,CAAA,CAAe,CAClE,QAAS,IAAA,CAAK,OAAA,CACd,cAAe,CI1sBC,IJ4sBuB,IAAA,CAAK,kBAAA,CAAmB,CAkBrE,MAAM,KAAK,CAAA,CAST,CACA,IAAM,EAAQA,KAAK,aAAA,CAAc,GAEjC,EAFsC,CAElC,CAKF,MAAO,CAAE,KAAM,EAJF,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAe,EAAA,CAAA,CAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CAEmC,CAA4B,MAAO,KAAM,OACvE,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAmBV,MAAM,OAAO,CAAA,CASX,CACA,IAAM,EAAQA,KAAK,aAAA,CAAc,GAEjC,EAFsC,CAElC,cACI,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAS,CACpD,QAASA,KAAK,OAAA,CACf,CAAC,CAEK,CAAE,MAAM,EAAM,MAAO,YACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,IAAU,EAAJ,WAAqB,EAAqB,CACjE,IAAM,EAAgB,EAAM,aAAA,CAE5B,GAAI,CAAC,IAAK,IAAI,CAAC,QAAA,OAAA,EAAA,KAAA,EAAS,EAAe,MAAA,CAAO,AAA/B,CACb,MAAO,CAAE,AADI,MACE,QAAO,EAAO,CAIjC,CALiB,KAKX,AALW,GA2DrB,aACE,CAAA,CACA,CAAA,CACiC,CACjC,IAAM,EAAQ,IAAA,CAAK,aAAA,CAAc,GAC3BqB,EADgC,AACP,EAAE,CAE3B,EAAA,OAAA,EAAA,KAAA,EAAqB,EAAS,CAA9B,OAA8B,CAA9B,CACF,CAAA,SAAA,CADE,CACU,CAAqB,GAD/B,GACkB,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACrD,GAEuB,GACzB,EADE,GACF,EAAa,IAAA,CAAK,GAIpB,IAAM,EADsB,KAA8B,EAA9B,GAHW,MAGX,EAAA,KAAA,EAAO,EAAS,CAAhB,QAAgB,AAAhB,EACa,UADb,KAC8B,AAD9B,SAEtB,EAAsB,IAAA,CAAK,0BAAA,CAAA,OAAA,EAAA,KAAA,EAA2B,EAAS,CAApC,QAAoC,AAApC,GAAiD,CAAA,CAAE,CAAC,CAEzD,GAC1B,EADE,AAF6B,GAG/B,EAAa,AAHkB,IAGlB,CAAK,GAGpB,IAAI,EAAc,EAAa,IAAA,CAAK,IAAI,AAHA,CAQxC,MAJI,AAAgB,GAClB,MAAA,EAAc,CAAA,CAAA,EAAI,EAAA,CAAA,EAGb,CACL,KAAM,CAAE,UAAW,UAAU,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAW,QAAA,EAAU,EAAA,EAAQ,EAAA,CAAA,CAAc,CAAE,CAC1F,CA0BH,MAAM,OAAO,CAAA,CASX,CACA,GAAI,OAOK,CAAE,KANI,MAAM,EACjBrB,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAUA,KAAK,QAAA,CAAA,CAAA,CAC3B,CAAE,SAAU,CAAA,CAAO,CACnB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,cACR,IACVA,KAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,MAAO,CAAE,KAAM,KAAM,QAAO,AAG9B,OAAM,GA8HV,MAAM,KACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CACF,IAAM,EAAA,EAAA,EAAA,EAAA,CAAA,EAAY,GAA2B,GAAA,CAAA,EAAA,CAAS,OAAQ,GAAQ,EAAA,GAQtE,MAAO,CAAE,KAPI,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAeA,KAAK,QAAA,CAAA,CAAA,CAChC,EACA,CAAE,QAASA,KAAK,OAAA,CAAS,CACzB,GAEa,MAAO,EADrB,UAEM,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAWV,MAAM,OACJ,CAAA,CACA,CAAA,CAUA,IACI,CACF,IAAM,EAAA,EAAA,CAAA,EAAY,SAQX,CAAE,KAPI,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,gBAAA,EAAkBA,KAAK,QAAA,CAAA,CAAA,CACnC,EACA,CAAE,QAASA,KAAK,OAAA,CAAS,CACzB,GAEa,MAAO,EADrB,GAC2B,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,SAGjB,GAIA,eAAA,CAAe,CAAA,CACvB,OAAO,KAAA,SAAA,CAAe,GAGxB,MAHiC,GAGxB,CAAA,CAAc,OACrB,AAAsB,YACpB,CADE,AACF,OADS,OACF,OAAO,IAAA,CAAK,GAAM,EAAD,MAAC,CAAS,SAAS,CAEtC,KAAK,GAGN,EAHW,YAGG,CAAA,CAAc,CAClC,MAAO,CAAA,EAAG,IAAA,CAAK,QAAA,CAAS,CAAA,EAAG,EAAK,OAAA,CAAQ,OAAQ,GAAG,CAAA,CAAA,qBAGzB,CAAA,CAAc,QACjC,EAAA,OAAA,CAAa,WAAY,GAAG,CAAC,OAAA,CAAQ,OAAQ,IAAI,CAGlD,2BAA2B,CAAA,CAA6B,CAC9D,IAAMsB,EAAmB,EAAE,CAqB3B,OApBI,EAAU,KAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,MAAA,EAAS,EAAU,KAAA,CAAA,CAAA,CAAQ,CAGrC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,OAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,QAAA,EAAW,EAAU,OAAA,CAAA,CAAA,CAAU,CAGtC,EAAO,IAAA,CAAK,IAAI,GM5wC3B,IAAa,EAAU,SCLVC,EAAkB,CAC7B,gBAAiB,CAAA,WAAA,EAAc,EAAA,CAAA,CAChC,CCID,IAAqB,EAArB,MAAsC,AAMpC,YACE,CAAA,CACA,EAAqC,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,MAPQ,kBAAA,EAAqB,EAQ7B,MAAM,EAAU,IAAI,IAAI,IAAI,MAI5B,EAAA,KAAA,EAAI,AAAJ,EAAU,MAAV,QAAU,CAAV,CAEE,CADuB,GADzB,sBACkD,IAAA,CAAK,EAAQ,QAAA,CAAS,EAChD,CAAC,EAAQ,QAAA,CAAS,QAAA,CAAS,oBAAoB,CACnE,EAAA,EAAQ,QAAA,CAAW,EAAQ,QAAA,CAAS,OAAA,CAAQ,YAAa,oBAAA,CAAoB,CAIjF,IAAA,CAAK,GAAA,CAAM,EAAQ,IAAA,CAAK,OAAA,CAAQ,MAAO,GAAG,CAC1C,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAeA,GAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ7B,EAAaO,QAAM,SAQN,QAC1B,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAmCT,MAAM,YAAY,CAAA,CAShB,CACA,GAAI,CACF,IAAM,EAAcD,KAAK,8BAAA,CAA+B,GAIxD,KAJgE,CAIzD,CAAE,KAHI,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,EAAS,EAAA,CAAA,CAAe,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAqCV,MAAM,UAAU,CAAA,CASd,CACA,GAAI,CAEF,MAAO,CAAE,KADI,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAM,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAC1E,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAyCV,MAAM,aACJ,CAAA,CACA,EAKI,CACF,QAAQ,CAAA,CACT,CAUD,CACA,GAAI,CAcF,MAAO,CAAE,KAbI,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CACZ,IACE,EACA,KAAM,EACN,KAAM,EAAQ,IAAA,CACd,OAAQ,EAAQ,MAAA,CAChB,gBAAiB,EAAQ,aAAA,CACzB,mBAAoB,EAAQ,gBAAA,CAC7B,CACD,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAuCV,MAAM,aACJ,CAAA,CACA,CAAA,CAcA,CACA,GAAI,CAaF,MAAO,CAAE,KAZI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,IACE,EACA,KAAM,EACN,OAAQ,EAAQ,MAAA,CAChB,gBAAiB,EAAQ,aAAA,CACzB,mBAAoB,EAAQ,gBAAA,CAC7B,CACD,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA4BV,MAAM,YAAY,CAAA,CAShB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAMe,EACjBf,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAG,MAAA,CAAA,CACzB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA6BV,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,KAAM,QAGvB,AAH8B,OAGxB,GAIF,+BAA+B,CAAA,CAAqC,CAC1E,IAAM0B,EAAiC,CAAA,CAAE,CAkBzC,OAjBI,IACE,KADO,KACI,IACb,EAAO,EAAP,GAAO,CAAQ,OAAO,EAAQ,MAAA,CAAM,CAElC,WAAY,IACd,EAAO,EAAP,IAAO,CAAS,OAAO,EAAQ,OAAA,CAAO,CAEpC,EAAQ,MAAA,CACV,CAAA,GAAO,MAAA,CAAS,EAAQ,MAAA,EAEtB,EAAQ,UAAA,CACV,EAAA,EAAO,UAAA,CAAa,EAAQ,UAAA,EAE1B,EAAQ,SAAA,CACV,EAAA,EAAO,SAAA,CAAY,EAAQ,SAAA,GAGxB,OAAO,IAAA,CAAK,GAAQ,IAAD,EAAC,CAAS,EAAI,IAAM,IAAI,gBAAgB,GAAQ,IAAD,IAAC,EAAU,CAAG,KElbtE,EAArB,MAA4C,AAuB1C,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAnBvE,kBAAA,EAAqB,EAoB7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAeH,GAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ7B,EAAaO,GAcrB,KAd2B,SAcN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAqCT,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAEF,MAAO,CAAE,KADI,MAAMc,EAAKf,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CAAU,MAAE,CAAA,CAAM,CAAE,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAC/E,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAkDV,MAAM,YAAY,CAAA,CAehB,CACA,GAAI,CAEF,IAAM,EAAc,IAAI,eACxB,EADyC,MACzC,EAAA,KAAA,EAAI,EAAS,CAAb,IAAa,IAAb,AAAuB,KAAA,EAAW,CAAA,EAAY,EAA9C,CAA8C,CAAI,GAAlD,KAA2D,EAAQ,KAAA,CAAM,QAAA,EAAU,CAAC,CACpF,OAAA,EAAA,KAAA,EAAI,EAAS,CAAb,KAAa,GAAb,CAAwB,KAAA,EAAW,CAAA,EAAY,CAA/C,EAA+C,CAAI,EAAnD,OAA6D,EAAQ,MAAA,CAAO,QAAA,EAAU,CAAC,QACvF,EAAA,KAAA,EAAI,EAAS,CAAb,QAAA,CAAa,CAAY,EAAA,EAAY,GAAA,CAAI,EAAzC,KAAA,MAAuD,EAAQ,UAAA,CAAW,CAC1E,SAAA,GAAA,EAAA,EAAI,EAAS,EAAb,OAAa,CAAW,EAAA,EAAxB,AAAoC,GAAA,CAAI,CAAxC,WAAqD,EAAQ,SAAA,CAAU,EACvE,QAAA,IAAA,CAAA,EAAI,EAAS,GAAb,GAAa,CAAQ,EAAA,EAAY,GAAA,CAAI,AAArC,KAAA,IAA+C,EAAQ,MAAA,CAAO,CAE9D,IAAM,EAAc,EAAY,QAAA,EAAU,CACpC,EAAM,EAAc,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAgB,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CAI5E,MAAO,CAAE,KAFI,MAAM,EAAIA,KAAK,KAAA,CAAO,EAAK,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAE7C,MAAO,KAAM,OAC3B,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAmCV,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA+HV,KAAK,CAAA,CAA+C,YAElD,GAAI,CAAC,CvB7UP,EAAI,IAAqC,SACvC,CADiB,OACV,AADiB,GAKX,IAAX,EAAW,MAAA,EAAgB,CChBJ,CDgBe,MAAA,CAAS,KACjD,AuBuUuB,AvBnUrB,ECrByD,ADqBzD,IAAA,CAJK,IuBuU2B,CAChC,CvBpUsB,CAOtB,EAAA,QAAA,AANF,CAME,AANF,MAME,CANK,CAMkC,QAAA,CAAS,KAAK,CACvD,CAAA,OAAO,sBAOc,IAAA,CAAK,CChCO,CDQ1B,EuB6UL,MAAM,IAAI,EACR,qJAED,CAOH,IAAM,EAAU,IAAI,EAAmB,CACrC,QAAS,IAAA,CAAK,GAAA,CACd,YAAa,EACb,KAAM,CACJ,KAAM,SACN,WAAY,SAAYA,EAAK,OAAA,CAC9B,CACD,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CAEI,EAAqB,IAAA,CAAK,kBAAA,CAuBhC,OArBuB,IAAI,MAAM,EAAS,CACxC,IAAI,CAAA,CAAQ,CAAA,EAAgC,AAC1C,IAAM,EAAQ,CAAA,CAAO,EAAA,OACrB,AAAqB,WACnB,CADE,AACF,OADS,EACF,EAGF,MAAO,GAAG,KACf,GAAI,CAD+B,AAGjC,MAAO,CAAE,KADI,MAAO,EAAmB,KAAA,CAAM,EAAQ,GACtC,EAD2C,IACpC,KAAM,OACrB,EAAO,CACd,GAAI,EACF,MAAM,EAER,MAAO,CAAE,EAFP,GAEa,KAAa,QAAuB,IAI1D,CAAC,GCvbN,IAAa,EAAkB,CAC7B,gBAAiB,CAAA,WAAA,EAAc,EAAA,CAAA,CAC/B,eAAgB,mBACjB,CCDD,IAAa,EAAb,cAAyC,MAAM,AAG7C,YAAY,CAAA,CAAiB,CAC3B,KAAA,CAAM,QAAQ,AAHN,uBAAA,EAA0B,EAIlC,IAAA,CAAK,IAAA,CAAO,wBAShB,SAAgB,EAAsB,CAAA,EAA8C,AAClF,MAAwB,UAAjB,OAAO,GAAgC,AAAV,UAAkB,4BAA6B,EAOrF,IAAa,EAAb,cAA4C,EAI1C,YAAY,CAAA,CAAiB,CAAA,CAAgB,CAAA,CAJiB,AAIG,CAC/D,KAAA,CAAM,GACN,IAAA,CADc,AACT,IAAA,CAAO,yBACZ,IAAA,CAAK,MAAA,CAAS,EACd,IAAA,CAAK,UAAA,CAAa,EAGpB,QAAS,CACP,MAAO,CACL,KAAM,IAAA,CAAK,IAAA,CACX,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,IAAA,CAAK,MAAA,CACb,WAAY,IAAA,CAAK,UAAA,CAClB,GAQQ,EAAb,cAAgD,EAG9C,YAAY,CAAA,CAAiB,CAAA,CAAwB,CACnD,CAJgE,IAIhE,CAAM,GACN,IAAA,CAAK,AADS,IACT,CAAO,6BACZ,IAAA,CAAK,aAAA,CAAgB,IC/CzB,IAAa,EAAA,AAAgB,GAC3B,AAAI,EACF,CAAQ,GAAG,IAAS,EAApB,CAFwD,AAExD,EAAmC,GAErC,CAAQ,CAFkC,EAAR,AAEvB,IAAS,MAAM,GAAG,GCezB,EDf8B,ACe9B,AAAoB,GACxB,EAAI,GAAA,EAAO,EAAI,OAAA,EAAW,EAAI,iBAAA,EAAqB,EAAI,KAAA,EAAS,KAAK,SAAA,CAAU,GAQ3E,CAR+E,CAQjE,MAClB,EACA,EACA,KAWA,GANE,GACA,AAAiB,CALhB,gBAKM,GACP,WAAY,GACZ,OAAQ,GACyB,UAAjC,OAAQ,EAAc,MAAA,EAEF,CAAA,OAAA,EAAA,KAAA,EAAC,EAAS,CAAV,QAAA,IAAU,EAAe,CAC7C,IAAM,CADc,CACJ,EAAc,EADV,IACU,EAAU,IAIN,WAChC,CADE,OAAO,EAAc,IAAA,CACvB,AAJoB,EAKjB,IAAA,EAAM,CACN,IAAA,CAAA,AAAM,IACL,IADkB,AACZ,EAAA,OAAA,EAAA,KAAA,CAAA,CAAa,EAAK,KAAlB,KAAkB,GAAlB,CAAkB,CAAA,GAAlB,IAAkB,KAAA,EAAc,CAAd,CAAmB,IAAA,GAAQ,AAA3B,EAAoC,GAC5D,AADwB,EACjB,IAAI,EAAuB,EAAiB,GAAM,CAAF,CAAU,KACjE,CACD,KAF6E,AAE7E,CAF8E,AAE9E,KAIC,CAJW,CAIJ,IAAI,EADK,EAAc,UAAA,EAAc,CAAA,KAAA,EAAQ,EAAO,MAAA,CAAA,CAChB,EAFxB,EAAS,IAEuB,EACnD,CAKJ,EAAO,IAAI,EANuD,AAKlD,CALmD,CAKrC,UAAA,EAAc,CAAA,KAAA,EAAQ,EAAO,MAAA,CAAA,CAChB,EAFxB,EAAS,IAEuB,MAGrD,EAAO,GAHyD,CAAC,AAGtD,EAA2B,EAAiB,GAAQ,GAAF,EA4CjE,CA5CyE,CAAC,aA4C3D,EACb,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,OAAO,IAAI,QAAA,CAAS,EAAS,WAAW,AACtC,EAAQ,GAnCJU,EAA+B,AAmCtB,CAnCwB,SAAQ,QAAA,CAAA,MAmCN,EAnCM,IAAA,CAAA,EAAS,EAAS,GAAlB,IAAkB,GAAW,CAAA,CAAE,CAAE,CAEhF,AAAI,AAAW,CAFgC,KAAA,EAmCd,GAjCT,CAAC,AAiCqC,EAhCrD,GAGL,AA6B+D,AAhCjE,CAAA,AD/DS,AAAiB,AC+FwC,ID9FpE,GAAqB,GADkC,GCkErC,IDjEd,CCiEmB,EAAE,IDjEd,GAAgC,KACzC,EAD+B,EAC/B,OAAO,EAGT,IAAM,EAAY,OAAO,cAAA,CAAe,GACxC,GAD8C,GAC9C,CACiB,OAAd,GACC,IAAc,OAAO,SAAA,EACgB,OAArC,OAAO,cAAA,CAAe,EAAe,CAAA,EACvC,CAAA,CAAE,GADgC,IACzB,WAAA,IAAe,CAAA,CAAA,EACxB,CAAA,CAAE,OAAO,QAAA,IAAY,CAAA,CAAA,OCwDrB,EAAO,OAAA,CAAA,EAAA,CAAY,eAAgB,kBAAA,EAAA,QAAA,IAAA,CAAA,EAAuB,EAAS,GAAhC,IAAgC,EACnE,EAAO,IAAA,AAD4B,CACrB,IADqB,CAChB,SAAA,CAAU,IAE7B,CAFkC,CAE3B,IAAA,GAAO,AAGhB,EAAA,EAAA,CAAA,EAAY,GAsBsC,MAC7C,AAvBkB,IAuBlB,CAAA,AAAM,IACL,GAAI,CAAC,EAAO,CADI,CACJ,CAAI,MAAM,EACtB,GAAA,QAAA,IAAA,CAAA,EAAI,EAAS,GAAb,UAAa,CAAe,CAA5B,KAAA,CAAmC,EAEnC,IAAM,EAAc,EAAO,OAAA,CAAQ,GAAA,CAAI,eAAe,QACjD,AAAL,AAAI,GAAiB,EAAY,QAAA,CAAS,CAAtB,kBAAyC,CAC3D,AAEK,CAFL,CAEY,IAAA,EAAM,CAFX,CAAA,CAAE,EAGX,CACD,IAAA,CAAA,AAAM,GAAS,EAAQ,IACvB,CAD4B,CAAC,GAC7B,CAAA,AAAO,GAAU,EAAY,EAAO,EAAQ,KAC/C,CA6BJ,EA9B2D,CAAC,YA8BtC,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,OAAO,EAAe,EAAS,OAAQ,EAAK,EAAS,EAAY,GC/InE,ED+IwE,EC/InD,GAArB,MAOE,AAPkC,YAOtB,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,GAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,EAAaT,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,YAAY,CAAA,CAA8D,CAC9E,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,EAAKD,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,SACJ,CAAA,CACA,CAAA,CAC8C,CAC9C,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,SAAA,CAAA,CACZ,kBAAE,YAAkB,EAAW,CAC/B,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YAAY,CAAA,CAAwE,CACxF,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YAAY,CAAA,CAA0B,CAAA,CAAoD,CAC9F,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,kBAAE,YAAkB,EAAW,CAC/B,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,KC9GS,GAArB,MAAmC,AAOjC,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,GAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,EAAaC,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,WAAW,CAAA,CAA6D,CAC5E,GAAI,CAEF,GAAI,EAAQ,OAAA,CAAQ,MAAA,CAAS,GAAK,EAAQ,OAAA,CAAQ,MAAA,CAAS,IACzD,MAAM,AAAI,MAAM,oDAAoD,CAMtE,MAAO,CAAE,KAHI,MAAM,EAAKD,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,WAAA,CAAA,CAAc,EAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,WAAW,CAAA,CAAsE,CACrF,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,WAAA,CAAA,CAAc,EAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YAAY,CAAA,CAAwE,CACxF,GAAI,CAEF,GAAI,AAAyB,KAAA,MAAjB,YAAA,CAA4B,CACtC,GAAI,EAAQ,YAAA,CAAe,GAAK,EAAQ,YAAA,CAAe,GACrD,MAAU,AAAJ,MAAU,wCAAwC,CAE1D,GAA6B,KAAA,GAC3B,CADE,EAAQ,YAAA,GACN,EAAQ,YAAA,CAAe,GAAK,EAAQ,YAAA,EAAgB,EAAQ,YAAA,CAC9D,CAAA,MAAM,AAAI,MAAM,CAAA,mCAAA,EAAsC,EAAQ,YAAA,CAAe,EAAA,CAAA,CAAI,CAQvF,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,aAAa,CAAA,CAA0E,CAC3F,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,CAAA,CAAgB,EAAS,CACvE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,cAAc,CAAA,CAAgE,CAClF,GAAI,CAEF,GAAI,EAAQ,IAAA,CAAK,MAAA,CAAS,GAAK,EAAQ,IAAA,CAAK,MAAA,CAAS,IACnD,MAAM,AAAI,MAAM,kDAAkD,CAMpE,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,cAAA,CAAA,CAAiB,EAAS,CACxE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,KCpIS,GAArB,MAAqC,AAOnC,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,GAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,EAAaC,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,aAAa,CAAA,CAA2D,CAC5E,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBD,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,mBAAA,CAAA,CACZ,kBAAE,CAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,UAAU,CAAA,CAAgF,CAC9F,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,gBAAA,CAAA,CACZ,kBAAE,CAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YACJ,EAAoC,CAAA,CAAE,CACW,CACjD,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,EAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,kBAAA,CAAA,CAAqB,EAAS,CAC5E,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,aAAa,CAAA,CAA2D,CAC5E,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,mBAAA,CAAA,CACZ,kBAAE,CAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,KCnCC,GAAb,cAA0C,GAkBxC,YAAY,CAAA,AAlB4C,CAkB/B,EAAuC,CAAA,CAAE,CAAE,CAClE,KAAA,CAAM,EAAK,EAAQ,OAAA,EAAW,CAAA,CAAE,CAAE,EAAQ,KAAA,CAAM,CAqBlD,KAAK,CAAA,CAA6C,CAChD,OAAO,IAAI,GAAkB,IAAA,CAAK,GAAA,CAAK,IAAA,CAAK,OAAA,CAAS,EAAkB,IAAA,CAAK,KAAA,CAAM,CAwBpF,MAAM,aAAa,CAAA,CAA2D,CAC5E,OAAO,AAAP,KAAO,CAAM,aAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAa,GAyB5B,MAAM,UAAU,CAAA,CAAgF,CAC9F,OAAO,AAAP,KAAO,CAAM,UAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAU,GA2BzB,MAAM,YACJ,EAAoC,CAAA,CAAE,CACW,CACjD,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAY,GAwB3B,MAAM,aAAa,CAAA,CAA2D,CAC5E,OAAA,AAAO,KAAA,CAAM,aAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAa,KAajB,GAAb,cAAuC,GAgBrC,YAhBoD,AAiBlD,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,GACpB,IAAA,CAD0B,AACrB,gBAAA,CAAmB,EA8B1B,MAAe,YAAY,CAAA,CAAuD,CAChF,OAAA,AAAO,KAAA,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAFW,AAEOD,IAFP,CAEY,gBAAA,IAuB3B,MAAe,YAAY,EAAwD,CAAA,CAAE,CAAE,CACrF,OAAA,AAAO,KAAA,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,AAFP,IAAA,CAEY,gBAAA,IAwB3B,MAAe,SAAS,CAAA,CAAmB,CACzC,OAAA,AAAO,KAAA,CAAM,SAAb,CAAa,GAAb,CAAa,AAAb,KAAsBA,IAAT,CAAc,gBAAA,CAAkB,GAsB/C,MAAe,YAAY,CAAA,CAAmB,CAC5C,OAAA,AAAO,KAAA,CAAM,YAAb,CAAa,GAAb,CAAA,KAAa,AAAYA,IAAZ,CAAiB,gBAAA,CAAkB,GAkClD,MAAM,CAAA,CAAqC,CACzC,OAAO,IAAI,GACT,IAAA,CAAK,GAAA,CACL,IAAA,CAAK,OAAA,CACL,IAAA,CAAK,gBAAA,CACL,EACA,IAAA,CAAK,KAAA,CACN,GAaQ,GAAb,cAAsC,GAkBpC,WAlBkD,CAmBhD,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,GACpB,IAAA,CAD0B,AACrB,gBAAA,CAAmB,EACxB,IAAA,CAAK,SAAA,CAAY,EA8BnB,MAAe,WAAW,CAAA,CAAoE,CAC5F,OAAO,AAAP,KAAO,CAAM,WAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBD,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,IA0BpB,MAAe,WAAW,CAAA,CAAoE,CAC5F,OAAO,AAAP,KAAO,CAAM,WAAb,CAAa,GAAb,CAAA,IAAa,CAAb,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,KAGK,SAAA,IA0BpB,MAAe,YACb,EAAsE,CAAA,CAAE,CACxE,CACA,OAAA,AAAO,KAAA,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,IA6BpB,MAAe,aACb,CAAA,CACA,CACA,OAAA,AAAO,KAAA,CAAM,aAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAHW,AAGAA,IAHA,CAGK,SAAA,IAyBpB,MAAe,cACb,CAAA,CACA,CACA,OAAO,AAAP,KAAO,CAAM,cAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,MC1lBT,GAAb,cAAmC,EAejC,YACE,CAAA,CACA,CAjBgD,CAiBX,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,EAAO,GAc7B,EAdkC,GAc7B,CAAA,CAA4B,CAC/B,OAAO,IAAI,EAAe,IAAA,CAAK,GAAA,CAAK,IAAA,CAAK,OAAA,CAAS,EAAI,IAAA,CAAK,KAAA,CAAM,CAcnE,IAAI,SAAgC,CAClC,OAAO,IAAI,GAAqB,IAAA,CAAK,GAAA,CAAM,UAAW,CACpD,QAAS,IAAA,CAAK,OAAA,CACd,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CAcJ,IAAI,WAAoC,CACtC,OAAO,IAAI,EAAuB,IAAA,CAAK,GAAA,CAAM,WAAY,IAAA,CAAK,OAAA,CAAS,IAAA,CAAK,KAAA,CAAM,sCnC1EtF,IAAI,GAAS,GAGX,GADE,AAAgB,YAClB,QADE,KACO,OACoB,YAC7B,CADS,AACT,OADgB,SACP,MACqB,aAArB,OAAO,WAA6B,AAAsB,cACnE,CAAA,WADuD,OAAA,CAC9C,eAEA,OAKX,IAAa,GAAyB,CACpC,QAH6B,CAAE,AAGtB,gBAHuC,CAAA,YAAA,EAAe,OAAO,CAAA,EAAG,CAAA,CAAW,AAG3E,CACV,CAED,GAAkC,CAChC,OAAQ,QAAA,CACT,CAEYT,GAAkD,CAC7D,kBAAkB,EAClB,gBAAgB,EAChB,mBAAoB,GACpB,CJwBA,QIxBU,YAGCC,GAAkD,CAAA,CAAE,yrCS/BjE,IAAa,GAAb,cAAwC,GAAA,OAAA,CAAW,AACjD,YAAY,CR2OF,CAAA,CQ1OR,ER0OQ,GQ1OR,CAAA,KC+BiB,CT2NV,ES3NX,MA2EE,YACYoB,CAAAA,CACAC,CAAAA,CACV,CAAA,CACA,WAHU,IAAA,CAAA,WAAA,CAAA,EACA,IAAA,CAAA,WAAA,CAAA,EAGV,MAAM,EHnCV,AInCM,ADsEc,CCtER,QJmCI,AAAoB,CAAA,EAA0B,AAC5D,IAAA,EAAA,MAAA,EAAA,KAAA,EAAmB,EAAa,IAAA,EAAM,IAElC,CAAC,EACH,MAAA,AAAU,MAAM,4BAGlB,GAAI,CAAC,EAAW,KAAA,CAAM,gBAAgB,CACpC,MAAM,AAAI,MAAM,0DAA0D,CAG5E,GAAI,CACF,OAAO,IAAI,IAjFN,AAiFU,EAjFN,QAAA,CAAS,OAiFiB,AAjFV,AAAM,EAAM,SAiFS,CAAC,GACzC,CACN,MAAM,MAAM,qDGqBwB,GACpC,GAAI,CAAC,EAAa,GAD8B,GACxB,AAAI,MAAM,4BAElC,IAAA,CAAK,WAAA,CAAc,IAAI,IAAI,cAAe,GAC1C,IAAA,CAAK,WAAA,CAAY,QAAA,CAAW,IAAA,CAAK,WAAA,CAAY,QAAA,CAAS,OAAA,CAAQ,OAAQ,KAAK,MACtE,OAAA,CAAU,IAAI,IAAI,UAAW,QAC7B,UAAA,CAAa,IAAI,IAAI,aAAA,QACrB,YAAA,CAAe,IAAI,IAAI,eAAgB,GAG5C,MAAM,EAAoB,CAAA,CCvExB,EDuEwB,EAAM,EAAQ,QAAA,CAAS,KAAA,CAAM,IAAI,CAAC,CFmBhD,CAAA,CEnBmD,WAAA,CAAA,CAQzD,EAAW,SHrHL,AAMd,CAAA,CACA,CAAA,EAC6C,QAC7C,GAAM,CACJ,GDgBE,AChBE,CAAA,CACJ,KAAM,CAAA,CACN,SAAU,CAAA,CACV,OAAQ,CAAA,CAAA,CACN,EACE,CACJ,CDWE,EAAA,CAAA,CCVF,KAAMZ,CAAAA,CACN,SAAUC,CAAAA,CACV,OAAQC,CAAAA,CAAAA,CACN,EAEEC,EAAsD,CAC1D,GAAA,GAAA,GAAA,CAAA,EACKC,GACA,GAEL,KAAA,GAAA,GAAA,CAAA,EACKJ,GACA,GAEL,SAAA,GAAA,GAAA,CAAA,EACKC,GACA,GAEL,QAAS,CAAA,CAAE,CACX,OAAA,GAAA,GAAA,GAAA,CAAA,EACKC,GACA,GAAA,CAAA,EAAA,CACH,QAAA,GAAA,GAAA,CAAA,EAAA,OAAA,QAAA,EAAA,KAAA,EACMA,EAAwB,OAAA,EAAA,EAAW,CAAA,CAAE,AAAb,EAAa,GAD3C,GAC8B,CAAa,IAD3C,IAC2C,EAAA,KAAA,EACrC,EAAe,MADS,CACT,AADsB,EACtB,EAAW,AADF,CACE,CAAX,AAAa,CAAA,AAFlC,CAC2C,EAI7C,EALE,EAEqB,QAGV,IAJgC,KAAA,AAIpB,IAU3B,KAbyB,EAMzB,EAAY,CANa,UAMb,CACV,EAAO,WAAA,CAAc,EAAQ,WAAA,CAG7B,OAAQ,EAAe,WAAA,CAGzB,SG+DwC,EAAA,EAAW,CAAA,CAAE,CAPlC,CACf,AAMmD,GAN/C,GCvEJ,ADwEA,GAK4D,MALlD,GACV,KAAA,GAAA,GAAA,CAAA,EAAW,IAAA,CAAA,EAAA,CAAsB,WAAY,CAAA,GAC7C,OAAQ,UAKL,IC3EH,MD2EG,CAAA,OAAA,EAAa,EAAS,IAAA,CAAK,UAAA,EAAA,EAAc,EAAd,MAC3B,EAD2B,KAC3B,CAAA,MAAA,CAAA,EAAU,EAAS,MAAA,CAAO,EADC,KACD,AADC,EACD,EAAW,CAAA,CAAX,AAAa,CAEvC,EAAS,KAFiB,MAEjB,EAAa,KAOpB,WAAA,CAAc,CATU,CASD,IATC,OASD,MAEvB,IAAA,CAAO,IAAI,MAA0B,CAAA,CAAE,CAAS,CACnD,IAAA,CAAM,EAAG,WACD,AAAI,MACR,CAAA,0GAAA,EAA6G,OAC3G,GACA,EAAD,cAAC,CAAA,CACH,KAdL,IAAA,CAAK,IAAA,CAAA,IAAA,CAAY,uBAAA,CAAA,MAAA,CAAA,EACf,EAAA,IAAA,EAAA,EAAiB,CAAA,CAAE,CACnB,IAAA,CAAK,OAAA,CACL,EAAS,MAAA,CAAO,KAAA,CACjB,CAeH,IAAA,CAAK,KAAA,CAAQ,ALlJjB,CAAA,CACE,EACA,EACA,KAEA,IAAMH,EAfN,EACE,CAAQ,CADN,EACS,EAcC,EAd2B,AAcd,GJ2HS,EIzIoB,EAAtD,CAEF,CAAQ,CAFqD,EAElD,IAA4B,SAAS,GAa1C,AJ+H2B,EIxI1B,AAJ8C,eAe9C,IAFoB,EAEb,EAAO,ECHF,ODGW,EAC5B,IAAA,EAAA,MAAA,AAHoD,CAGpD,EAAqB,MAAM,GAAA,CAAgB,CAAA,EAAK,EAC5C,CADuC,CAC7B,IAAI,EAAA,CADyB,KACzB,EAAA,KAAA,EAAmB,EAAM,OAAA,CAAQ,CAUnD,CAX2C,KAAA,CAGvC,AAAC,EAAQ,GAAA,CAAI,WACf,EAAQ,GAAA,CAAI,SAAU,GAGpB,AAAC,EAAQ,GCJX,ADIW,CAAI,GAHmB,aAGH,CAC/B,CAAA,EAAQ,GAAA,CAAI,gBAAiB,CAAA,OAAA,EAAU,EAAA,CAAA,CAAc,CAGvD,EAAa,EAAA,GAAA,GAAA,CAAA,EAAY,GAAA,CAAA,EAAA,SAAM,CAAA,GAAU,IK8Hd,EAAa,CClFD,GAAA,CDkFM,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK,CAAE,EAAS,MAAA,CAAO,KAAA,CAAM,CAC/F,IAAA,CAAK,QAAA,CAAW,IAAA,CAAK,mBAAA,CAAA,GAAA,CACnB,QAAS,IAAA,CAAK,OAAA,CACd,YAAa,GCjFL,CAAA,CDiFU,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK,EACzC,EAAS,QAAA,GAEV,IAAA,CAAK,WAAA,CAEP,CAAA,IAAA,CAAK,WAAA,EAAa,CACf,IAAA,CAAA,AAAM,GAAU,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,IACtC,EAD4C,CAAC,EAC7C,CAAA,AAAO,GAAM,QAAQ,IAAA,CAAK,6CAA8C,EAAE,CAAC,CAGhF,IAAA,CAAK,IAAA,CAAO,IAAI,EAAgB,IAAI,IAAI,UAAW,GAAS,IAAA,CAAD,AAAO,CAChE,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,EAAS,EAAA,CAAG,MAAA,CACpB,MAAO,IAAA,CAAK,KAAA,GAGd,IAAA,CAAK,OAAA,CAAU,CG9HT,GH8HaiB,GACjB,IAAA,CAAK,UAAA,CAAW,IAAA,CAChB,IAAA,CAAK,OAAA,CACL,IAAA,CAAK,KAAA,OAAA,EAAA,KAAA,EACL,EAAS,CADJ,MACI,CACV,CAED,AAAK,AAJE,EAIO,UAJP,CAIO,CACZ,CAAA,EALK,EAKL,CAAK,SC9FgC,WAAA,GDqGzC,IAAI,WAAA,QACK,IAAI,EAAA,eAAA,CAAgB,IAAA,CAAK,YAAA,CAAa,IAAA,CAAM,CACjD,QAAS,IAAA,CAAK,OAAA,CACd,YAAa,CC/FN,GAAA,CD+FW,KAAA,GAiBtB,KAAK,CAAA,CAAqE,CACxE,OAAO,IAAA,CAAK,IAAA,CAAK,IAAA,CAAK,GAWxB,MAXiC,CAY/B,CAAA,CAMA,CACA,OAAO,IAAA,CAAK,IAAA,CAAK,MAAA,CAAsB,GA2BzC,IASE,CAAA,CACA,EAAa,CAAA,CAAE,CACf,EAII,OACI,EACN,KAAK,EACL,MAAO,KAAA,EACR,CASD,QACO,IAAA,CAAK,IAAA,CAAK,GAAA,CAAI,EAAI,EAAM,GAkBjC,KAlByC,GAkBjC,CAAA,CAAA,EAA6C,CAAE,OAAQ,CAAA,CAAE,CAAE,CAAmB,QAC7E,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,EAAM,CMxPH,INwPQ,WAMT,CAC/B,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,EAAa,CASpC,cAAc,CAAA,CAAiE,QACtE,IAAA,CAAK,QAAA,CAAS,aAAA,CAAc,GAMrC,KAN6C,cAMkB,CAC7D,OAAO,IAAA,CAAK,QAAA,CAAS,iBAAA,EAAmB,CAG1C,MAAA,iBAAgC,SAC9B,GAAIlB,KAAK,WAAA,CAAA,OACA,MAAMA,KAAK,WAAA,GAGpB,GAAM,MAAE,CAAA,CAAA,CAAS,MAAMA,KAAK,IAAA,CAAK,UAAA,GAEjC,OAAA,MAAA,CAAA,EAAA,MAAA,CAAA,EAAO,EAAK,OAAA,EAAA,KAAA,EAAA,EAAS,YAAA,EAAA,EAAgBA,EAAhB,GAAqB,KAArB,MAAqB,CAGpC,mBAHe,KAAA,AAIrB,kBACE,CAAA,gBACA,CAAA,oBACA,CAAA,SACA,CAAA,aACA,CAAA,YACA,CAAA,UACA,CAAA,CACA,MAAA,OACA,CAAA,cACA,CAAA,CAAA,CAEF,CAAA,CACA,CAAA,CACA,CACA,IAAM,EAAc,eACH,CAAA,OAAA,EAAU,IAAA,CAAK,CMtP1B,UAAA,CAAA,CAAA,CNuPJ,OAAQ,CAAA,EAAG,IAAA,CAAK,WAAA,CAAA,CAAA,SAEX,IAAI,GAAmB,CAC5B,IAAK,GG5H+B,CH4H/B,CAAK,OAAA,CAAQ,IAAA,CAClB,QAAA,GAAA,GAAA,CAAA,EAAc,GAAgB,cAClB,EACZ,kCACA,qBACA,wBAEA,WACA,OACA,QACA,iBAEA,MAAA,EAGA,6BAA8B,OAAO,IAAA,CAAK,IAAA,CAAK,OAAA,EAAS,IAAA,CAAA,AACrD,GAA8B,gBAChC,EADU,EAAI,WAAA,EAAa,IAKxB,oBAAoB,CAAA,CAAgC,CAC1D,OAAO,IAAI,EAAA,OAAA,CAAe,IAAA,CAAK,WAAA,CAAY,IAAA,CAAA,GAAA,GAAA,CAAA,EACtC,GAAA,CAAA,EAAA,CACH,OAAA,GAAA,GAAA,CAAA,EAAa,CAAE,OAAQ,IAAA,CAAK,WAAA,CAAa,QAAA,EAAA,KAAA,EAAK,EAAS,CAAd,KAAc,CAAA,EAAd,CACzC,CAGI,UAJqC,KAAA,OAId,CAI7B,GM5O2B,CACvB,GNwOS,IAAA,CAAK,IAAA,CAAK,iBAAA,CAAA,CAAmB,EAAO,KAC/C,IAAA,CAAK,EADsD,iBACtD,CAAoB,EAAO,eAAA,EAAA,KAAA,EAAU,EAAS,CAAnB,QAAA,GAAmB,CAAa,GAK5D,KAL4B,KAAA,UAMlC,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,CACa,oBAAV,GAAyC,cAAV,CAAU,CAAA,EAC1C,IAAA,CAAK,kBAAA,GAAuB,GAE5B,IAAA,AADA,CACK,kBAAA,CAAqB,OACrB,QAAA,CAAS,OAAA,CAAQ,IACH,cAAc,CAAxB,OK9N8B,CAAA,CL+NlC,QAAA,CAAS,OAAA,EAAS,CACT,UAAW,CAArB,GAAqB,IAAA,CAAK,IAAA,CAAK,OAAA,EAAS,CAC5C,IAAA,CAAK,kBAAA,CAAqB,KAAA,KOvXhC,IAAa,GAAA,CAeX,EACA,EACA,IAEO,IAAI,GACT,CAFkE,CAGlE,EACA,EA+BA,EA1BJ,IAJG,KAIM,KAOgB,aAAnB,OAAO,MAPoC,EAQ7C,OAAO,EJuPqC,AInP9C,IAAM,EAAkB,OAAA,CAAgB,OAAA,CACxC,SAAI,EACF,OAAO,EAGT,IAAM,EAAe,EAJE,AAIa,KAJb,AAIa,CAAM,IAJN,QAIkB,OACtD,CAAI,CAAC,EALkD,CAUhC,IADF,AARnB,MAKA,CAAA,EAG4B,CAAA,CAAa,EAAA,CAHlC,AAGsC,GAAG,MAKlD,QAAQ,IAAA,CACN,8OAGD","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]}